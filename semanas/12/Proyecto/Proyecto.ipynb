{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET CINEMA\n",
    "1. CONTEXTO Y USO \n",
    "\n",
    "En La industria cinematográfica podemos utilizar  los modelos predictivos. Al igual que en otras industrias, comercio  la banca y la restaurantes, la previsión de ventas puede ayudar a los cines a reducir costes y mejorar el retorno de la inversión. adicionalmnete optimizar la proyección en diferentes lugares, así como la segmentación y fijación de precios del mercado de forma eficaz.\n",
    "\n",
    "Asimismo, los datos históricos de ventas y detalles de las películas, como el coste, el reparto y el equipo, y otros detalles del proyecto, como el calendario, pueden ayudar a los productores a seleccionar un reparto y un equipo de alto rendimiento y planificar un mejor retorno de la inversión de los proyectos. También ayuda a asignar lugares de proyección en puntos y áreas de gran demanda.\n",
    "\n",
    "Fuente: Kaggle \n",
    "link: https://www.kaggle.com/datasets/arashnic/cinema-ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Objetivo Clasificacion \n",
    "// consulto a chatgpt que podria clasificar, (predicion de ocupacion, prediccion de ventas de entradas, prediccion de ventas de ingresos) esta ultima me llama la atencion\n",
    "\n",
    "Predicción de Ingresos: (total_sales)\n",
    "\n",
    "Entrada: Datos como la cantidad de entradas vendidas, el precio del boleto, y la ubicación del cine.\n",
    "Predicción: El modelo podría predecir que los ingresos generados estarán en la categoría \"Alto\" (más del 80% del rango de ingresos posibles).\n",
    "\n",
    "\n",
    "https://chatgpt.com/c/a892a6d5-7528-4ef0-aa71-84a33b222163\n",
    "\n",
    "se deberia predecir dentro de las 5 categorias Bajo, Medio Bajo, Medio, Medio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. IMPORTACIONES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "#from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142524 entries, 0 to 142523\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   film_code     142524 non-null  int64  \n",
      " 1   cinema_code   142524 non-null  int64  \n",
      " 2   total_sales   142524 non-null  int64  \n",
      " 3   tickets_sold  142524 non-null  int64  \n",
      " 4   tickets_out   142524 non-null  int64  \n",
      " 5   show_time     142524 non-null  int64  \n",
      " 6   occu_perc     142399 non-null  float64\n",
      " 7   ticket_price  142524 non-null  float64\n",
      " 8   ticket_use    142524 non-null  int64  \n",
      " 9   capacity      142399 non-null  float64\n",
      " 10  date          142524 non-null  object \n",
      " 11  month         142524 non-null  int64  \n",
      " 12  quarter       142524 non-null  int64  \n",
      " 13  day           142524 non-null  int64  \n",
      "dtypes: float64(3), int64(10), object(1)\n",
      "memory usage: 15.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_code</th>\n",
       "      <th>cinema_code</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>tickets_sold</th>\n",
       "      <th>tickets_out</th>\n",
       "      <th>show_time</th>\n",
       "      <th>occu_perc</th>\n",
       "      <th>ticket_price</th>\n",
       "      <th>ticket_use</th>\n",
       "      <th>capacity</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>1.425240e+05</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142399.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142399.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "      <td>142524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1518.985111</td>\n",
       "      <td>320.378427</td>\n",
       "      <td>1.234728e+07</td>\n",
       "      <td>140.137570</td>\n",
       "      <td>0.237413</td>\n",
       "      <td>3.932103</td>\n",
       "      <td>19.965986</td>\n",
       "      <td>81234.599886</td>\n",
       "      <td>139.900157</td>\n",
       "      <td>854.723605</td>\n",
       "      <td>6.776852</td>\n",
       "      <td>2.634721</td>\n",
       "      <td>16.112585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.184450</td>\n",
       "      <td>159.701229</td>\n",
       "      <td>3.065486e+07</td>\n",
       "      <td>279.758733</td>\n",
       "      <td>2.923206</td>\n",
       "      <td>3.056276</td>\n",
       "      <td>22.653445</td>\n",
       "      <td>33236.599278</td>\n",
       "      <td>279.564935</td>\n",
       "      <td>953.118103</td>\n",
       "      <td>2.195843</td>\n",
       "      <td>0.809692</td>\n",
       "      <td>8.949471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1471.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>483.870968</td>\n",
       "      <td>-219.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1485.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>1.260000e+06</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>276.994486</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1498.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>3.720000e+06</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>79454.235185</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>525.714286</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1556.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>1.110000e+07</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.210000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1038.961039</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1589.000000</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>1.262820e+09</td>\n",
       "      <td>8499.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>147.500000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>8499.000000</td>\n",
       "      <td>9692.097160</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           film_code    cinema_code   total_sales   tickets_sold  \\\n",
       "count  142524.000000  142524.000000  1.425240e+05  142524.000000   \n",
       "mean     1518.985111     320.378427  1.234728e+07     140.137570   \n",
       "std        36.184450     159.701229  3.065486e+07     279.758733   \n",
       "min      1471.000000      32.000000  2.000000e+04       1.000000   \n",
       "25%      1485.000000     181.000000  1.260000e+06      18.000000   \n",
       "50%      1498.000000     324.000000  3.720000e+06      50.000000   \n",
       "75%      1556.000000     474.000000  1.110000e+07     143.000000   \n",
       "max      1589.000000     637.000000  1.262820e+09    8499.000000   \n",
       "\n",
       "         tickets_out      show_time      occu_perc   ticket_price  \\\n",
       "count  142524.000000  142524.000000  142399.000000  142524.000000   \n",
       "mean        0.237413       3.932103      19.965986   81234.599886   \n",
       "std         2.923206       3.056276      22.653445   33236.599278   \n",
       "min         0.000000       1.000000       0.000000     483.870968   \n",
       "25%         0.000000       2.000000       3.750000   60000.000000   \n",
       "50%         0.000000       3.000000      10.350000   79454.235185   \n",
       "75%         0.000000       5.000000      28.210000  100000.000000   \n",
       "max       311.000000      60.000000     147.500000  700000.000000   \n",
       "\n",
       "          ticket_use       capacity          month        quarter  \\\n",
       "count  142524.000000  142399.000000  142524.000000  142524.000000   \n",
       "mean      139.900157     854.723605       6.776852       2.634721   \n",
       "std       279.564935     953.118103       2.195843       0.809692   \n",
       "min      -219.000000      -2.000000       2.000000       1.000000   \n",
       "25%        18.000000     276.994486       5.000000       2.000000   \n",
       "50%        50.000000     525.714286       7.000000       3.000000   \n",
       "75%       143.000000    1038.961039       9.000000       3.000000   \n",
       "max      8499.000000    9692.097160      11.000000       4.000000   \n",
       "\n",
       "                 day  \n",
       "count  142524.000000  \n",
       "mean       16.112585  \n",
       "std         8.949471  \n",
       "min         1.000000  \n",
       "25%         8.000000  \n",
       "50%        16.000000  \n",
       "75%        24.000000  \n",
       "max        31.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"cinemaTicket.csv\")\n",
    "df.info()\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. lIMPIEZA DE DATOS\n",
    "\n",
    ">Limpieza de datos (imputar o eliminar valores])\n",
    "Eliminación de Duplicados: Identificar y eliminar registros duplicados.\n",
    "Corrección de Errores: Corregir errores o inconsistencias en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film_code         0\n",
      "cinema_code       0\n",
      "total_sales       0\n",
      "tickets_sold      0\n",
      "tickets_out       0\n",
      "show_time         0\n",
      "occu_perc       125\n",
      "ticket_price      0\n",
      "ticket_use        0\n",
      "capacity        125\n",
      "date              0\n",
      "month             0\n",
      "quarter           0\n",
      "day               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  DataFrame df validacion de datos nulos\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino las filas vacias debido a que representan un 0.088 % de los datos de las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df = df.dropna(subset=['occu_perc', 'capacity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino columnas innecesarias y reordeno el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['film_code', 'cinema_code', 'total_sales', 'tickets_sold',\n",
      "       'tickets_out', 'show_time', 'occu_perc', 'ticket_price', 'ticket_use',\n",
      "       'capacity', 'date', 'month', 'quarter', 'day'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_code</th>\n",
       "      <th>cinema_code</th>\n",
       "      <th>show_time</th>\n",
       "      <th>occu_perc</th>\n",
       "      <th>capacity</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>day</th>\n",
       "      <th>tickets_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1492</td>\n",
       "      <td>304</td>\n",
       "      <td>4</td>\n",
       "      <td>4.26</td>\n",
       "      <td>610</td>\n",
       "      <td>736819</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1492</td>\n",
       "      <td>352</td>\n",
       "      <td>5</td>\n",
       "      <td>8.08</td>\n",
       "      <td>519</td>\n",
       "      <td>736819</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1492</td>\n",
       "      <td>489</td>\n",
       "      <td>4</td>\n",
       "      <td>20.00</td>\n",
       "      <td>160</td>\n",
       "      <td>736819</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1492</td>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>11.01</td>\n",
       "      <td>108</td>\n",
       "      <td>736819</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1492</td>\n",
       "      <td>524</td>\n",
       "      <td>3</td>\n",
       "      <td>16.67</td>\n",
       "      <td>89</td>\n",
       "      <td>736819</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142519</th>\n",
       "      <td>1569</td>\n",
       "      <td>495</td>\n",
       "      <td>2</td>\n",
       "      <td>3.86</td>\n",
       "      <td>569</td>\n",
       "      <td>737002</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142520</th>\n",
       "      <td>1569</td>\n",
       "      <td>474</td>\n",
       "      <td>1</td>\n",
       "      <td>65.22</td>\n",
       "      <td>22</td>\n",
       "      <td>737002</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142521</th>\n",
       "      <td>1569</td>\n",
       "      <td>524</td>\n",
       "      <td>3</td>\n",
       "      <td>9.20</td>\n",
       "      <td>86</td>\n",
       "      <td>737002</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142522</th>\n",
       "      <td>1569</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>100</td>\n",
       "      <td>737002</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142523</th>\n",
       "      <td>1569</td>\n",
       "      <td>486</td>\n",
       "      <td>1</td>\n",
       "      <td>1.79</td>\n",
       "      <td>279</td>\n",
       "      <td>737002</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142399 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        film_code  cinema_code  show_time  occu_perc  capacity    date  month  \\\n",
       "0            1492          304          4       4.26       610  736819      5   \n",
       "1            1492          352          5       8.08       519  736819      5   \n",
       "2            1492          489          4      20.00       160  736819      5   \n",
       "3            1492          429          1      11.01       108  736819      5   \n",
       "4            1492          524          3      16.67        89  736819      5   \n",
       "...           ...          ...        ...        ...       ...     ...    ...   \n",
       "142519       1569          495          2       3.86       569  737002     11   \n",
       "142520       1569          474          1      65.22        22  737002     11   \n",
       "142521       1569          524          3       9.20        86  737002     11   \n",
       "142522       1569          529          2       5.00       100  737002     11   \n",
       "142523       1569          486          1       1.79       279  737002     11   \n",
       "\n",
       "        quarter  day  tickets_sold  \n",
       "0             2    5            26  \n",
       "1             2    5            42  \n",
       "2             2    5            32  \n",
       "3             2    5            12  \n",
       "4             2    5            15  \n",
       "...         ...  ...           ...  \n",
       "142519        4    4            22  \n",
       "142520        4    4            15  \n",
       "142521        4    4             8  \n",
       "142522        4    4             5  \n",
       "142523        4    4             5  \n",
       "\n",
       "[142399 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.drop(columns=['total_sales','tickets_out','ticket_use','ticket_price'], inplace=True)\n",
    "\n",
    " #Obtener el nombre de la tercera columna\n",
    "columna_a_predecir  = df.columns[2] #tickets_sold\n",
    "\n",
    "# Crear una nueva lista de columnas reordenada\n",
    "columnas_reordenadas = [col for col in df.columns if col != columna_a_predecir ] + [columna_a_predecir ]\n",
    "\n",
    "# Reordenar las columnas del DataFrame\n",
    "df = df[columnas_reordenadas]\n",
    "\n",
    "\n",
    "# Convertir características categóricas fecha a-->ordinal\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'] = df['date'].map(lambda x: x.toordinal())  # Convertir fechas a ordinales\n",
    "# Truncar la columna decimal a enteros\n",
    "df['capacity'] = df['capacity'].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores de x: ['film_code', 'cinema_code', 'show_time', 'occu_perc', 'capacity', 'date', 'month', 'quarter', 'day']\n",
      "valores de y: ['tickets_sold']\n"
     ]
    }
   ],
   "source": [
    "# Características y etiqueta\n",
    "X = ['film_code','cinema_code','show_time', 'occu_perc', 'capacity', 'date', 'month', 'quarter', 'day']\n",
    "y = ['tickets_sold']\n",
    "\n",
    "print('valores de x:',X)\n",
    "print('valores de y:',y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Original:\n",
      "[[1.492e+03 3.040e+02 4.000e+00 ... 2.000e+00 5.000e+00 2.600e+01]\n",
      " [1.492e+03 3.520e+02 5.000e+00 ... 2.000e+00 5.000e+00 4.200e+01]\n",
      " [1.492e+03 4.890e+02 4.000e+00 ... 2.000e+00 5.000e+00 3.200e+01]\n",
      " ...\n",
      " [1.569e+03 5.240e+02 3.000e+00 ... 4.000e+00 4.000e+00 8.000e+00]\n",
      " [1.569e+03 5.290e+02 2.000e+00 ... 4.000e+00 4.000e+00 5.000e+00]\n",
      " [1.569e+03 4.860e+02 1.000e+00 ... 4.000e+00 4.000e+00 5.000e+00]]\n",
      "\n",
      "Dataset Estandarizado:\n",
      "[[-0.74588967 -0.10255142  0.0216292  ... -0.78435478 -1.24178213\n",
      "  -0.4082007 ]\n",
      " [-0.74588967  0.19810563  0.3487642  ... -0.78435478 -1.24178213\n",
      "  -0.35099823]\n",
      " [-0.74588967  1.05623094  0.0216292  ... -0.78435478 -1.24178213\n",
      "  -0.38674977]\n",
      " ...\n",
      " [ 1.38212067  1.27546004 -0.30550581 ...  1.68658315 -1.35353137\n",
      "  -0.47255348]\n",
      " [ 1.38212067  1.30677848 -0.63264081 ...  1.68658315 -1.35353137\n",
      "  -0.48327894]\n",
      " [ 1.38212067  1.03743988 -0.95977581 ...  1.68658315 -1.35353137\n",
      "  -0.48327894]]\n",
      "\n",
      "Dataset Escalado:\n",
      "[[1.77966102e-01 5.09363296e-01 5.08474576e-02 ... 3.33333333e-01\n",
      "  1.33333333e-01 2.94186867e-03]\n",
      " [1.77966102e-01 5.99250936e-01 6.77966102e-02 ... 3.33333333e-01\n",
      "  1.33333333e-01 4.82466463e-03]\n",
      " [1.77966102e-01 8.55805243e-01 5.08474576e-02 ... 3.33333333e-01\n",
      "  1.33333333e-01 3.64791716e-03]\n",
      " ...\n",
      " [8.30508475e-01 9.21348315e-01 3.38983051e-02 ... 1.00000000e+00\n",
      "  1.00000000e-01 8.23723229e-04]\n",
      " [8.30508475e-01 9.30711610e-01 1.69491525e-02 ... 1.00000000e+00\n",
      "  1.00000000e-01 4.70698988e-04]\n",
      " [8.30508475e-01 8.50187266e-01 0.00000000e+00 ... 1.00000000e+00\n",
      "  1.00000000e-01 4.70698988e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir DataFrame a matriz numpy\n",
    "dataset = df.values\n",
    "\n",
    "# Estandarización\n",
    "standard_scaler = StandardScaler()\n",
    "dataset_standardized = standard_scaler.fit_transform(dataset)\n",
    "\n",
    "# Escalado\n",
    "minmax_scaler = MinMaxScaler()\n",
    "dataset_scaled = minmax_scaler.fit_transform(dataset)\n",
    "\n",
    "# Mostrar resultados\n",
    "print('Dataset Original:')\n",
    "print(dataset)\n",
    "\n",
    "print('\\nDataset Estandarizado:')\n",
    "print(dataset_standardized)\n",
    "\n",
    "print('\\nDataset Escalado:')\n",
    "print(dataset_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. TRASNFORMACION DE DATOS \n",
    ">Normalización/Estándarización: Escalar datos para que estén en un rango o distribución específica.\n",
    "Codificación de Variables Categóricas: Convertir variables categóricas en variables numéricas (e.g., One-Hot Encoding).\n",
    "Transformación de Fechas: Extraer características de fechas como año, mes, día, etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " aplico normalizacion con el metodo de:\n",
    " >Min-Max Scaling \n",
    "  Z-score\n",
    "\n",
    "  Estrategia: \n",
    "  No Normalizar: Identificadores y fechas.\n",
    "  Normalizar: Características numéricas continuas y rangos amplios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#la data se divide en datos numericos y categoricos, puedo usar ambos sin embargo se sugiere\n",
    "#1. separar los tipos de datos\n",
    "#2. standarizar o normalizar Z-score y luego normalizar Min-Max[0,1]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ALMACENAMOS EN UN ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.492e+03, 3.040e+02, 4.000e+00, ..., 2.000e+00, 5.000e+00,\n",
       "        2.600e+01],\n",
       "       [1.492e+03, 3.520e+02, 5.000e+00, ..., 2.000e+00, 5.000e+00,\n",
       "        4.200e+01],\n",
       "       [1.492e+03, 4.890e+02, 4.000e+00, ..., 2.000e+00, 5.000e+00,\n",
       "        3.200e+01],\n",
       "       ...,\n",
       "       [1.569e+03, 5.240e+02, 3.000e+00, ..., 4.000e+00, 4.000e+00,\n",
       "        8.000e+00],\n",
       "       [1.569e+03, 5.290e+02, 2.000e+00, ..., 4.000e+00, 4.000e+00,\n",
       "        5.000e+00],\n",
       "       [1.569e+03, 4.860e+02, 1.000e+00, ..., 4.000e+00, 4.000e+00,\n",
       "        5.000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:9] # todas las filas _:_ y 10 columnas   0:10\n",
    "Y  = dataset[:,9] # aignamos nuestra ultima columna de nuestra matriz a Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1779661 , 0.5093633 , 0.05084746, ..., 0.33333333, 0.33333333,\n",
       "        0.13333333],\n",
       "       [0.1779661 , 0.59925094, 0.06779661, ..., 0.33333333, 0.33333333,\n",
       "        0.13333333],\n",
       "       [0.1779661 , 0.85580524, 0.05084746, ..., 0.33333333, 0.33333333,\n",
       "        0.13333333],\n",
       "       ...,\n",
       "       [0.83050847, 0.92134831, 0.03389831, ..., 1.        , 1.        ,\n",
       "        0.1       ],\n",
       "       [0.83050847, 0.93071161, 0.01694915, ..., 1.        , 1.        ,\n",
       "        0.1       ],\n",
       "       [0.83050847, 0.85018727, 0.        , ..., 1.        , 1.        ,\n",
       "        0.1       ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99679, 9) (21360, 9) (21360, 9) (99679,) (21360,) (21360,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "#datos entrenamiento 99679\n",
    "#datos prueba 21360\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.CONSTRUIR Y ENTRENAR EL MODELO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 84347.0156 - mae: 134.2837 - val_loss: 65463.7852 - val_mae: 126.5361\n",
      "Epoch 2/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 56430.1523 - mae: 112.3194 - val_loss: 40586.4883 - val_mae: 84.9964\n",
      "Epoch 3/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 35742.4297 - mae: 82.8059 - val_loss: 34034.3047 - val_mae: 83.0501\n",
      "Epoch 4/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 30482.6270 - mae: 80.7570 - val_loss: 30948.9590 - val_mae: 81.1161\n",
      "Epoch 5/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 28272.1172 - mae: 78.7081 - val_loss: 29061.2676 - val_mae: 79.9400\n",
      "Epoch 6/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 27389.7559 - mae: 77.5912 - val_loss: 27396.3652 - val_mae: 78.1442\n",
      "Epoch 7/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 26051.3535 - mae: 77.1748 - val_loss: 26273.0059 - val_mae: 78.0333\n",
      "Epoch 8/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 25746.5586 - mae: 77.2462 - val_loss: 25340.9141 - val_mae: 77.2455\n",
      "Epoch 9/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 23899.0938 - mae: 75.4744 - val_loss: 24569.4141 - val_mae: 76.7447\n",
      "Epoch 10/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 22990.3418 - mae: 75.3624 - val_loss: 23857.8086 - val_mae: 75.9304\n",
      "Epoch 11/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 23002.4082 - mae: 74.8961 - val_loss: 23361.3223 - val_mae: 76.4446\n",
      "Epoch 12/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 22354.8887 - mae: 74.9350 - val_loss: 22795.2578 - val_mae: 74.7949\n",
      "Epoch 13/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 22334.2344 - mae: 74.8698 - val_loss: 22400.4590 - val_mae: 74.2227\n",
      "Epoch 14/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 21786.5723 - mae: 73.4875 - val_loss: 22031.7344 - val_mae: 74.1352\n",
      "Epoch 15/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 21247.6074 - mae: 72.8977 - val_loss: 21735.7227 - val_mae: 73.7685\n",
      "Epoch 16/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 21274.6602 - mae: 73.0719 - val_loss: 21504.8027 - val_mae: 72.9141\n",
      "Epoch 17/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20667.8516 - mae: 72.1721 - val_loss: 21248.3496 - val_mae: 72.8258\n",
      "Epoch 18/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 21210.6035 - mae: 72.6453 - val_loss: 21061.4336 - val_mae: 72.5461\n",
      "Epoch 19/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20649.4473 - mae: 71.3812 - val_loss: 20867.7832 - val_mae: 71.7481\n",
      "Epoch 20/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20785.1699 - mae: 71.2618 - val_loss: 20853.3926 - val_mae: 71.3440\n",
      "Epoch 21/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20565.5469 - mae: 70.9520 - val_loss: 20675.6602 - val_mae: 72.4215\n",
      "Epoch 22/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20546.6660 - mae: 71.0579 - val_loss: 20450.8887 - val_mae: 71.2272\n",
      "Epoch 23/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20644.0723 - mae: 70.6647 - val_loss: 20354.9629 - val_mae: 71.2555\n",
      "Epoch 24/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19730.3262 - mae: 69.9231 - val_loss: 20300.5312 - val_mae: 71.2686\n",
      "Epoch 25/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20268.6367 - mae: 70.1361 - val_loss: 20194.8066 - val_mae: 70.5840\n",
      "Epoch 26/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20364.6055 - mae: 70.2748 - val_loss: 20079.2070 - val_mae: 70.4339\n",
      "Epoch 27/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19883.0664 - mae: 69.8229 - val_loss: 20036.9238 - val_mae: 70.2384\n",
      "Epoch 28/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19453.2754 - mae: 68.9525 - val_loss: 20114.3359 - val_mae: 69.8493\n",
      "Epoch 29/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19815.4004 - mae: 69.1037 - val_loss: 19965.8047 - val_mae: 69.8261\n",
      "Epoch 30/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19920.2344 - mae: 69.7193 - val_loss: 19809.9375 - val_mae: 69.9589\n",
      "Epoch 31/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19606.2871 - mae: 69.1764 - val_loss: 19744.4668 - val_mae: 69.8033\n",
      "Epoch 32/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19377.7598 - mae: 68.9427 - val_loss: 19752.9609 - val_mae: 69.5896\n",
      "Epoch 33/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19675.1074 - mae: 69.5482 - val_loss: 19673.4082 - val_mae: 69.5800\n",
      "Epoch 34/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19525.7773 - mae: 68.8999 - val_loss: 19683.9395 - val_mae: 69.3927\n",
      "Epoch 35/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19700.6113 - mae: 69.3132 - val_loss: 19724.0527 - val_mae: 69.3633\n",
      "Epoch 36/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19670.5625 - mae: 69.5105 - val_loss: 19646.1836 - val_mae: 69.3014\n",
      "Epoch 37/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19614.6348 - mae: 68.9883 - val_loss: 19538.0430 - val_mae: 69.2827\n",
      "Epoch 38/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19337.2227 - mae: 68.8047 - val_loss: 19472.2793 - val_mae: 69.5317\n",
      "Epoch 39/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19208.3516 - mae: 68.9412 - val_loss: 19488.1641 - val_mae: 69.2134\n",
      "Epoch 40/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19287.9863 - mae: 68.6045 - val_loss: 19677.2949 - val_mae: 69.2224\n",
      "Epoch 41/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19857.6191 - mae: 69.4586 - val_loss: 19395.4453 - val_mae: 69.5256\n",
      "Epoch 42/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19168.0352 - mae: 68.5944 - val_loss: 19369.5723 - val_mae: 69.3063\n",
      "Epoch 43/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19213.3203 - mae: 68.3620 - val_loss: 19334.7168 - val_mae: 69.2552\n",
      "Epoch 44/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19611.7578 - mae: 69.2595 - val_loss: 19350.1406 - val_mae: 69.0382\n",
      "Epoch 45/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19061.3594 - mae: 68.3797 - val_loss: 19291.6504 - val_mae: 69.3993\n",
      "Epoch 46/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18838.4062 - mae: 68.2948 - val_loss: 19336.2207 - val_mae: 69.6865\n",
      "Epoch 47/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19356.9336 - mae: 69.0945 - val_loss: 19297.1953 - val_mae: 68.9347\n",
      "Epoch 48/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19341.5098 - mae: 68.7500 - val_loss: 19367.7715 - val_mae: 69.0497\n",
      "Epoch 49/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18716.9609 - mae: 67.9982 - val_loss: 19207.8809 - val_mae: 69.0250\n",
      "Epoch 50/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18959.9727 - mae: 68.4456 - val_loss: 19199.9492 - val_mae: 69.0591\n",
      "Epoch 51/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18805.5488 - mae: 68.2806 - val_loss: 19164.2578 - val_mae: 69.0492\n",
      "Epoch 52/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19041.0781 - mae: 68.3953 - val_loss: 19156.9531 - val_mae: 68.8172\n",
      "Epoch 53/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19497.2871 - mae: 68.7199 - val_loss: 19178.5820 - val_mae: 69.1968\n",
      "Epoch 54/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19107.0215 - mae: 68.3562 - val_loss: 19182.6719 - val_mae: 68.7468\n",
      "Epoch 55/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19085.6934 - mae: 68.2076 - val_loss: 19098.0781 - val_mae: 69.0743\n",
      "Epoch 56/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18705.9902 - mae: 68.0383 - val_loss: 19104.2031 - val_mae: 69.1534\n",
      "Epoch 57/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18843.7891 - mae: 68.1092 - val_loss: 19107.0312 - val_mae: 68.5862\n",
      "Epoch 58/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18967.7637 - mae: 68.2515 - val_loss: 19083.1797 - val_mae: 68.7137\n",
      "Epoch 59/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18789.7832 - mae: 67.8141 - val_loss: 19073.2305 - val_mae: 68.6738\n",
      "Epoch 60/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18823.0293 - mae: 68.1039 - val_loss: 19017.7148 - val_mae: 68.6979\n",
      "Epoch 61/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18826.6309 - mae: 68.2484 - val_loss: 19065.5547 - val_mae: 68.6212\n",
      "Epoch 62/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19431.2754 - mae: 68.5457 - val_loss: 19000.8203 - val_mae: 68.8759\n",
      "Epoch 63/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18774.3359 - mae: 68.0383 - val_loss: 19030.0859 - val_mae: 68.5608\n",
      "Epoch 64/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19029.1387 - mae: 68.3590 - val_loss: 18955.8613 - val_mae: 68.7181\n",
      "Epoch 65/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18873.2207 - mae: 68.1175 - val_loss: 19367.9375 - val_mae: 68.6250\n",
      "Epoch 66/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18649.7539 - mae: 67.8035 - val_loss: 18939.3184 - val_mae: 68.6127\n",
      "Epoch 67/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18635.9785 - mae: 67.8638 - val_loss: 19047.2441 - val_mae: 68.3970\n",
      "Epoch 68/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19000.9727 - mae: 68.0493 - val_loss: 18945.2539 - val_mae: 68.4142\n",
      "Epoch 69/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18843.0996 - mae: 67.8702 - val_loss: 18973.4551 - val_mae: 68.3776\n",
      "Epoch 70/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18692.6445 - mae: 67.6992 - val_loss: 18931.2949 - val_mae: 68.8979\n",
      "Epoch 71/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18770.7441 - mae: 68.1688 - val_loss: 18951.7871 - val_mae: 68.4140\n",
      "Epoch 72/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18821.9375 - mae: 68.1858 - val_loss: 18908.8848 - val_mae: 68.6443\n",
      "Epoch 73/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18816.7383 - mae: 68.1434 - val_loss: 18877.7012 - val_mae: 68.5631\n",
      "Epoch 74/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19257.8672 - mae: 68.1823 - val_loss: 18882.9609 - val_mae: 68.8659\n",
      "Epoch 75/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18564.2930 - mae: 67.6038 - val_loss: 18919.1484 - val_mae: 68.3454\n",
      "Epoch 76/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18796.1758 - mae: 67.8225 - val_loss: 18899.1602 - val_mae: 68.2290\n",
      "Epoch 77/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18902.3477 - mae: 68.0211 - val_loss: 18883.3750 - val_mae: 68.1750\n",
      "Epoch 78/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18333.8906 - mae: 67.6935 - val_loss: 18854.9785 - val_mae: 68.3471\n",
      "Epoch 79/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18566.5449 - mae: 67.5056 - val_loss: 18790.9102 - val_mae: 68.4689\n",
      "Epoch 80/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19146.6270 - mae: 68.7054 - val_loss: 18836.9746 - val_mae: 68.4417\n",
      "Epoch 81/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18334.8750 - mae: 67.2377 - val_loss: 18852.7539 - val_mae: 68.2717\n",
      "Epoch 82/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 19219.1973 - mae: 68.7831 - val_loss: 18922.7168 - val_mae: 68.1969\n",
      "Epoch 83/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18748.3184 - mae: 68.0016 - val_loss: 18793.3008 - val_mae: 68.2635\n",
      "Epoch 84/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18770.2324 - mae: 68.1580 - val_loss: 18728.9863 - val_mae: 68.2144\n",
      "Epoch 85/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18604.1738 - mae: 67.5311 - val_loss: 18765.2695 - val_mae: 68.4109\n",
      "Epoch 86/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18890.6758 - mae: 68.4787 - val_loss: 18746.6777 - val_mae: 67.9500\n",
      "Epoch 87/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18368.7891 - mae: 67.2690 - val_loss: 18737.1348 - val_mae: 68.2665\n",
      "Epoch 88/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18653.7715 - mae: 67.8307 - val_loss: 18883.7266 - val_mae: 68.1749\n",
      "Epoch 89/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18524.4980 - mae: 67.4844 - val_loss: 18687.8867 - val_mae: 68.1017\n",
      "Epoch 90/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18936.2969 - mae: 68.2738 - val_loss: 18781.8105 - val_mae: 68.1076\n",
      "Epoch 91/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18564.9902 - mae: 67.2784 - val_loss: 18698.5273 - val_mae: 68.1266\n",
      "Epoch 92/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18695.5664 - mae: 67.5053 - val_loss: 18685.7188 - val_mae: 68.1066\n",
      "Epoch 93/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18763.7578 - mae: 67.8639 - val_loss: 18695.1289 - val_mae: 67.9995\n",
      "Epoch 94/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18544.2148 - mae: 67.2759 - val_loss: 18677.8359 - val_mae: 68.0458\n",
      "Epoch 95/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18383.2988 - mae: 67.8122 - val_loss: 18711.6270 - val_mae: 68.0304\n",
      "Epoch 96/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18618.0117 - mae: 67.5183 - val_loss: 18684.9023 - val_mae: 68.1361\n",
      "Epoch 97/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18304.2129 - mae: 67.2353 - val_loss: 18669.8164 - val_mae: 67.8841\n",
      "Epoch 98/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18624.0098 - mae: 67.5821 - val_loss: 18696.0566 - val_mae: 68.0332\n",
      "Epoch 99/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18416.5957 - mae: 67.2167 - val_loss: 18905.2715 - val_mae: 68.0012\n",
      "Epoch 100/100\n",
      "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18592.0410 - mae: 67.8023 - val_loss: 18755.4043 - val_mae: 68.0710\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - loss: 18289.7832 - mae: 65.4271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[19141.822265625, 67.1837158203125]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#usa tensor flow en el backend\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Definir el callback de early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Monitorear la pérdida en los datos de validación\n",
    "    patience=10,            # Número de épocas que esperar antes de detener si no\n",
    "    restore_best_weights=True  # Restaurar los pesos del modelo en el punto donde la pérdida era mínima\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=(9,)),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dense(1, activation='linear')  # activation='linear -> regreseion  /  activation='sigmoid' -> clasificación binaria\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', #sgd es valido pero adam converge mas rapido\n",
    "              loss='mse',       #regresion usar  mse\n",
    "              metrics=['mae'])  \n",
    "\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=64, \n",
    "          epochs=100,\n",
    "          validation_data =(X_val, Y_val),\n",
    "          callbacks=[early_stopping])\n",
    "         # )\n",
    "          \n",
    "\n",
    "#evaluando el modelo\n",
    "model.evaluate(X_test, Y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHFCAYAAADv8c1wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABqBElEQVR4nO3deXxU1f3/8ddMkpkshCEQkiFsgiKCAZegLC5gQUBZita6oBGqxYUKpkK1alvRbwXFBa24V8E9rT+KtS4IbiiyikRZxBVZE8KSTEKWmcnM+f0x5MIQwIBJJhPez8fjPjJz7+feOXOl33l/zz33XJsxxiAiIiIih2WPdANEREREooFCk4iIiEgtKDSJiIiI1IJCk4iIiEgtKDSJiIiI1IJCk4iIiEgtKDSJiIiI1IJCk4iIiEgtKDSJiIiI1IJCk4hE1OzZs7HZbNhsNj7++OMa240xnHDCCdhsNgYMGFCnn22z2ZgyZcoR7/fTTz9hs9mYPXt2ndSJSHRQaBKRRiE5OZnnnnuuxvqFCxfyww8/kJycHIFWiYjso9AkIo3CZZddxpw5cygpKQlb/9xzz9G3b186dOgQoZaJiIQoNIlIo3DFFVcA8Nprr1nrPB4Pc+bM4ZprrjnoPrt372b8+PG0bdsWh8NB586dufPOO/F6vWF1JSUljBs3jlatWtGsWTOGDh3Kt99+e9Bjfvfdd4wePZq0tDScTifdunXj8ccfr6NvGbJo0SIGDhxIcnIyiYmJ9OvXj7fffjuspry8nMmTJ9OpUyfi4+Np2bIlvXr1Cjs/P/74I5dffjkZGRk4nU7S09MZOHAgeXl5ddpeEQmJjXQDREQAmjdvziWXXMLzzz/P9ddfD4QClN1u57LLLuORRx4Jq6+srOS8887jhx9+4O6776Znz558+umnTJs2jby8PCuEGGMYNWoUixcv5m9/+xtnnHEGn332GRdccEGNNqxbt45+/frRoUMHHnroIdxuN++99x4TJ05k586d3HXXXb/4ey5cuJDzzz+fnj178txzz+F0OnniiScYMWIEr732GpdddhkAt9xyCy+99BJ///vfOe200ygrK2PNmjXs2rXLOtaFF15IIBBg+vTpdOjQgZ07d7J48WKKi4t/cTtF5CCMiEgEzZo1ywBmxYoV5qOPPjKAWbNmjTHGmDPOOMOMHTvWGGPMySefbPr372/t99RTTxnA/Pvf/w473v33328AM3/+fGOMMe+++64BzKOPPhpWd++99xrA3HXXXda6IUOGmHbt2hmPxxNWe9NNN5n4+Hize/duY4wxGzZsMICZNWvWYb/bwer69Olj0tLSTGlpqbWuqqrKZGZmmnbt2plgMGiMMSYzM9OMGjXqkMfeuXOnAcwjjzxy2DaISN3R5TkRaTT69+/P8ccfz/PPP8/q1atZsWLFIS/NffjhhyQlJXHJJZeErR87diwAH3zwAQAfffQRAFdeeWVY3ejRo8PeV1ZW8sEHH3DRRReRmJhIVVWVtVx44YVUVlaydOnSX/T9ysrKWLZsGZdccgnNmjWz1sfExJCdnc2WLVv45ptvADjzzDN59913+fOf/8zHH39MRUVF2LFatmzJ8ccfzwMPPMDDDz/MqlWrCAaDv6h9InJ4Ck0i0mjYbDZ+97vf8fLLL/PUU09x4okncs455xy0dteuXbjdbmw2W9j6tLQ0YmNjrctYu3btIjY2llatWoXVud3uGserqqriscceIy4uLmy58MILAdi5c+cv+n5FRUUYY2jTpk2NbRkZGVY7AP7xj39w22238cYbb3DeeefRsmVLRo0axXfffQeEztUHH3zAkCFDmD59OqeffjqtW7dm4sSJlJaW/qJ2isjBKTSJSKMyduxYdu7cyVNPPcXvfve7Q9a1atWK7du3Y4wJW19YWEhVVRWpqalWXVVVVdhYIICCgoKw9ykpKcTExDB27FhWrFhx0KU6PB2tlJQU7HY7+fn5NbZt27YNwGp3UlISd999N+vXr6egoIAnn3ySpUuXMmLECGufjh078txzz1FQUMA333zDH//4R5544gn+9Kc//aJ2isjBKTSJSKPStm1b/vSnPzFixAjGjBlzyLqBAweyZ88e3njjjbD1L774orUd4LzzzgPglVdeCat79dVXw94nJiZy3nnnsWrVKnr27EmvXr1qLAf2Vh2ppKQkevfuzX/+85+wy23BYJCXX36Zdu3aceKJJ9bYLz09nbFjx3LFFVfwzTffUF5eXqPmxBNP5C9/+Qs9evTgiy+++EXtFJGD091zItLo3HfffT9bc/XVV/P4448zZswYfvrpJ3r06MGiRYuYOnUqF154IYMGDQJg8ODBnHvuudx6662UlZXRq1cvPvvsM1566aUax3z00Uc5++yzOeecc7jxxhs57rjjKC0t5fvvv+d///sfH3744S/+btOmTeP888/nvPPOY/LkyTgcDp544gnWrFnDa6+9Zl1u7N27N8OHD6dnz56kpKTw9ddf89JLL9G3b18SExP56quvuOmmm/jtb39Lly5dcDgcfPjhh3z11Vf8+c9//sXtFJGaFJpEJCrFx8fz0Ucfceedd/LAAw+wY8cO2rZty+TJk8OmBrDb7bz55pvccsstTJ8+HZ/Px1lnncU777zDSSedFHbM7t2788UXX/B///d//OUvf6GwsJAWLVrQpUuXX3xprlr//v358MMPueuuuxg7dizBYJBTTjmFN998k+HDh1t1v/rVr3jzzTeZMWMG5eXltG3blquvvpo777wTCI3JOv7443niiSfYvHkzNpuNzp0789BDDzFhwoQ6aauIhLOZAwcEiIiIiEgNGtMkIiIiUgsKTSIiIiK1oNAkIiIiUgsKTSIiIiK1oNAkIiIiUgsKTSIiIiK1oHma6lAwGGTbtm0kJyfXeB6WiIiINE7GGEpLS8nIyMBuP3R/kkJTHdq2bRvt27ePdDNERETkKGzevJl27dodcrtCUx1KTk4GQie9efPmEW6NiIiI1EZJSQnt27e3fscPRaGpDlVfkmvevLlCk4iISJT5uaE1GgguIiIiUgsKTSIiIiK1oNAkIiIiUgsa0yQiItLIBQIB/H5/pJsRteLi4oiJifnFx1FoEhERaaSMMRQUFFBcXBzppkS9Fi1a4Ha7f9E8igpNIiIijVR1YEpLSyMxMVETJx8FYwzl5eUUFhYC0KZNm6M+lkKTiIhIIxQIBKzA1KpVq0g3J6olJCQAUFhYSFpa2lFfqtNAcBERkUaoegxTYmJihFvSNFSfx18yNkyhSUREpBHTJbm6URfnMaKhqaqqir/85S906tSJhIQEOnfuzD333EMwGLRqjDFMmTKFjIwMEhISGDBgAGvXrg07jtfrZcKECaSmppKUlMTIkSPZsmVLWE1RURHZ2dm4XC5cLhfZ2dk1BtZt2rSJESNGkJSURGpqKhMnTsTn89Xb9xcREZHoEdHQdP/99/PUU08xc+ZMvv76a6ZPn84DDzzAY489ZtVMnz6dhx9+mJkzZ7JixQrcbjfnn38+paWlVk1OTg5z584lNzeXRYsWsWfPHoYPH04gELBqRo8eTV5eHvPmzWPevHnk5eWRnZ1tbQ8EAgwbNoyysjIWLVpEbm4uc+bMYdKkSQ1zMkREROSQBgwYQE5OTmQbYSJo2LBh5pprrglbd/HFF5urrrrKGGNMMBg0brfb3Hfffdb2yspK43K5zFNPPWWMMaa4uNjExcWZ3Nxcq2br1q3GbrebefPmGWOMWbdunQHM0qVLrZolS5YYwKxfv94YY8w777xj7Ha72bp1q1Xz2muvGafTaTweT62+j8fjMUCt60VERA6loqLCrFu3zlRUVES6KUcEOOwyZsyYozrurl27TElJyVG363Dns7a/3xHtaTr77LP54IMP+PbbbwH48ssvWbRoERdeeCEAGzZsoKCggMGDB1v7OJ1O+vfvz+LFiwFYuXIlfr8/rCYjI4PMzEyrZsmSJbhcLnr37m3V9OnTB5fLFVaTmZlJRkaGVTNkyBC8Xi8rV648aPu9Xi8lJSVhS33YucfLpl3lVPoDP18sIiISQfn5+dbyyCOP0Lx587B1jz76aFh9bQdmt2zZkuTk5Ppocq1FNDTddtttXHHFFZx00knExcVx2mmnkZOTwxVXXAGE5qcASE9PD9svPT3d2lZQUIDD4SAlJeWwNWlpaTU+Py0tLazmwM9JSUnB4XBYNQeaNm2aNUbK5XLRvn37Iz0FtXLxE4s594GPWLutfkKZiIhIXXG73dbicrmw2WzW+8rKSlq0aMG///1vBgwYQHx8PC+//DK7du3iiiuuoF27diQmJtKjRw9ee+21sOMeeHnuuOOOY+rUqVxzzTUkJyfToUMHnnnmmXr9bhENTf/61794+eWXefXVV/niiy944YUXePDBB3nhhRfC6g4c8W6M+dlR8AfWHKz+aGr2d/vtt+PxeKxl8+bNh23T0UqIC80noZ4mEZFjmzGGcl9Vgy/GmDr9HrfddhsTJ07k66+/ZsiQIVRWVpKVlcVbb73FmjVruO6668jOzmbZsmWHPc5DDz1Er169WLVqFePHj+fGG29k/fr1ddrW/UV0css//elP/PnPf+byyy8HoEePHmzcuJFp06YxZswY3G43EOoF2n8Gz8LCQqtXyO124/P5KCoqCuttKiwspF+/flbN9u3ba3z+jh07wo5z4H+coqIi/H5/jR6oak6nE6fTebRfv9bi40LZVqFJROTYVuEP0P1v7zX45667ZwiJjrqLDDk5OVx88cVh6yZPnmy9njBhAvPmzeP1118PG1pzoAsvvJDx48cDoSA2Y8YMPv74Y0466aQ6a+v+ItrTVF5ejt0e3oSYmBhryoFOnTrhdrtZsGCBtd3n87Fw4UIrEGVlZREXFxdWk5+fz5o1a6yavn374vF4WL58uVWzbNkyPB5PWM2aNWvIz8+3aubPn4/T6SQrK6uOv/mRid/b01Sh0CQiIk1Ar169wt4HAgHuvfdeevbsSatWrWjWrBnz589n06ZNhz1Oz549rdfVlwGrH5dSHyLa0zRixAjuvfdeOnTowMknn8yqVat4+OGHueaaa4DQCcjJyWHq1Kl06dKFLl26MHXqVBITExk9ejQALpeLa6+9lkmTJtGqVStatmzJ5MmT6dGjB4MGDQKgW7duDB06lHHjxvH0008DcN111zF8+HC6du0KwODBg+nevTvZ2dk88MAD7N69m8mTJzNu3DiaN28egbOzjxWafApNIiLHsoS4GNbdMyQin1uXkpKSwt4/9NBDzJgxg0ceeYQePXqQlJRETk7Oz86VGBcXF/beZrOFzfVY1yIamh577DH++te/Mn78eAoLC8nIyOD666/nb3/7m1Vz6623UlFRwfjx4ykqKqJ3797Mnz8/bAT9jBkziI2N5dJLL6WiooKBAwcye/bssGfLvPLKK0ycONG6y27kyJHMnDnT2h4TE8Pbb7/N+PHjOeuss0hISGD06NE8+OCDDXAmDs8a01RVf/8QRESk8bPZbHV6mayx+PTTT/n1r3/NVVddBUAwGOS7776jW7duEW5ZuIie+eTkZB555BEeeeSRQ9bYbDamTJnClClTDlkTHx/PY489FjYp5oFatmzJyy+/fNj2dOjQgbfeeuvnmt3gEhx7Q5N6mkREpAk64YQTmDNnDosXLyYlJYWHH36YgoKCRhea9Oy5KFA9EFxjmkREpCn661//yumnn86QIUMYMGAAbrebUaNGRbpZNTS9Pr4mKF5TDoiISBQaO3YsY8eOtd4fd9xxB52+oGXLlrzxxhuHPdbHH38c9v6nn36qUZOXl3fkjTwC6mmKAgm6e05ERCTiFJqigHqaREREIk+hKQrsmxFcd8+JiIhEikJTFIh3aJ4mERGRSFNoigLxsXsfo1Kl0CQiIhIpCk1RIEE9TSIiIhGn0BQFEjQQXEREJOIUmqJAvAaCi4iIRJxCUxSI1zxNIiIiEafQFAU0uaWIiBxLBgwYQE5OTqSbUYNCUxSofvacxjSJiEhjN2LECAYNGnTQbUuWLMFms/HFF180cKvqhkJTFKi+e06hSUREGrtrr72WDz/8kI0bN9bY9vzzz3Pqqady+umnR6Blv5xCUxSIjw2FJn/AUBXQYHAREWm8hg8fTlpaGrNnzw5bX15ezr/+9S9GjRrFFVdcQbt27UhMTKRHjx689tprkWnsEVJoigLVPU0AlVUKTSIixyxjwFfW8IsxtW5ibGwsV199NbNnz8bst9/rr7+Oz+fj97//PVlZWbz11lusWbOG6667juzsbJYtW1YfZ6xOxUa6AfLznLH7sm2FL0Azp/6ziYgck/zlMDWj4T/3jm3gSKp1+TXXXMMDDzzAxx9/zHnnnQeELs1dfPHFtG3blsmTJ1u1EyZMYN68ebz++uv07t27zptel9TTFAVsNpsGg4uISNQ46aST6NevH88//zwAP/zwA59++inXXHMNgUCAe++9l549e9KqVSuaNWvG/Pnz2bRpU4Rb/fPUZRElEuJiqPQHFZpERI5lcYmhXp9IfO4Ruvbaa7npppt4/PHHmTVrFh07dmTgwIE88MADzJgxg0ceeYQePXqQlJRETk4OPp+vHhpetxSaokRCXAxF+DVXk4jIscxmO6LLZJF06aWXcvPNN/Pqq6/ywgsvMG7cOGw2G59++im//vWvueqqqwAIBoN89913dOvWLcIt/nm6PBclrFnB9dBeERGJAs2aNeOyyy7jjjvuYNu2bYwdOxaAE044gQULFrB48WK+/vprrr/+egoKCiLb2FpSaIoS1vPndPeciIhEiWuvvZaioiIGDRpEhw4dAPjrX//K6aefzpAhQxgwYABut5tRo0ZFtqG1pMtzUaJ62gH1NImISLTo27dv2LQDAC1btuSNN9447H4ff/xx/TXqF1BPU5SovnvOW6XQJCIiEgkKTVEiQWOaREREIkqhKUpYA8F195yIiEhEKDRFCWsguF8DwUVERCJBoSlKJKinSUTkmHTgQGo5OnVxHhWaokT13XOaEVxE5NgQFxcHQHl5eYRb0jRUn8fq83o0NOVAlIiP1bPnRESOJTExMbRo0YLCwkIAEhMTsdlsEW5V9DHGUF5eTmFhIS1atCAmJuaoj6XQFCXiNU+TiMgxx+12A1jBSY5eixYtrPN5tBSaokR8rMY0iYgca2w2G23atCEtLQ2/3x/p5kStuLi4X9TDVE2hKUrsG9Oku+dERI41MTExdfKjL79MRAeCH3fccdhsthrLH/7wByB0HXLKlClkZGSQkJDAgAEDWLt2bdgxvF4vEyZMIDU1laSkJEaOHMmWLVvCaoqKisjOzsblcuFyucjOzqa4uDisZtOmTYwYMYKkpCRSU1OZOHEiPp+vXr//kUiI00BwERGRSIpoaFqxYgX5+fnWsmDBAgB++9vfAjB9+nQefvhhZs6cyYoVK3C73Zx//vmUlpZax8jJyWHu3Lnk5uayaNEi9uzZw/DhwwkE9oWL0aNHk5eXx7x585g3bx55eXlkZ2db2wOBAMOGDaOsrIxFixaRm5vLnDlzmDRpUgOdiZ9X/RgVXZ4TERGJENOI3Hzzzeb44483wWDQBINB43a7zX333Wdtr6ysNC6Xyzz11FPGGGOKi4tNXFycyc3NtWq2bt1q7Ha7mTdvnjHGmHXr1hnALF261KpZsmSJAcz69euNMca88847xm63m61bt1o1r732mnE6ncbj8dS6/R6PxwBHtE9tfbR+u+l421vmwkc/qfNji4iIHMtq+/vdaOZp8vl8vPzyy1xzzTXYbDY2bNhAQUEBgwcPtmqcTif9+/dn8eLFAKxcuRK/3x9Wk5GRQWZmplWzZMkSXC4XvXv3tmr69OmDy+UKq8nMzCQjI8OqGTJkCF6vl5UrVx6yzV6vl5KSkrClvmhySxERkchqNKHpjTfeoLi4mLFjxwJQUFAAQHp6elhdenq6ta2goACHw0FKSspha9LS0mp8XlpaWljNgZ+TkpKCw+Gwag5m2rRp1jgpl8tF+/btj+AbHxnrMSqackBERCQiGk1oeu6557jgggvCenuAGhN5GWN+dnKvA2sOVn80NQe6/fbb8Xg81rJ58+bDtuuXsO6eq9LdcyIiIpHQKELTxo0bef/99/n9739vrauegOrAnp7CwkKrV8jtduPz+SgqKjpszfbt22t85o4dO8JqDvycoqIi/H5/jR6o/TmdTpo3bx621Bfr8px6mkRERCKiUYSmWbNmkZaWxrBhw6x1nTp1wu12W3fUQWjc08KFC+nXrx8AWVlZxMXFhdXk5+ezZs0aq6Zv3754PB6WL19u1SxbtgyPxxNWs2bNGvLz862a+fPn43Q6ycrKqp8vfYSc+909Z/TwRhERkQYX8cktg8Egs2bNYsyYMcTG7muOzWYjJyeHqVOn0qVLF7p06cLUqVNJTExk9OjRALhcLq699lomTZpEq1ataNmyJZMnT6ZHjx4MGjQIgG7dujF06FDGjRvH008/DcB1113H8OHD6dq1KwCDBw+me/fuZGdn88ADD7B7924mT57MuHHj6rX36EhU9zQBeKuC1hgnERERaRgRD03vv/8+mzZt4pprrqmx7dZbb6WiooLx48dTVFRE7969mT9/PsnJyVbNjBkziI2N5dJLL6WiooKBAwcye/bssJlTX3nlFSZOnGjdZTdy5EhmzpxpbY+JieHtt99m/PjxnHXWWSQkJDB69GgefPDBevzmR2b/kFTpDyg0iYiINDCb0bWeOlNSUoLL5cLj8dRLD9UJd7xDVdCw9PaBuF3xdX58ERGRY1Ftf78bxZgmqR3N1SQiIhI5Ck1RJN6hO+hEREQiRaEpilQ/f66ySqFJRESkoSk0RZEEzQouIiISMQpNUSReY5pEREQiRqEpiljPn/PrUSoiIiINTaEpiujuORERkchRaIoi8fs9SkVEREQalkJTFKnuafIqNImIiDQ4haYokqB5mkRERCJGoSmKOGM1pklERCRSFJqiSHVPk+6eExERaXgKTVFEd8+JiIhEjkJTFLEeo6LQJCIi0uAUmqKI9RgVhSYREZEGp9AURfQYFRERkchRaIoiVmjSlAMiIiINTqEpiliX56p095yIiEhDU2iKItaUA+ppEhERaXAKTVHEunuuSqFJRESkoSk0RRGNaRIREYkchaYoorvnREREIkehKYpUDwT36jEqIiIiDU6hKYpUhyZfIEhVQMFJRESkISk0RZHqy3OgaQdEREQamkJTFHHG7vvPpUepiIiINCyFpihit9usaQd0B52IiEjDio10A6QWljwOpflw5nXEx8VQ6Q+qp0lERKSBKTRFg8+fh13fw4kXkBAXQzF+KnUHnYiISIPS5bloEJcY+usvt+6g01xNIiIiDUuhKRo4kkJ/fWU4FZpEREQiQqEpGoT1NO19/pxCk4iISIOKeGjaunUrV111Fa1atSIxMZFTTz2VlStXWtuNMUyZMoWMjAwSEhIYMGAAa9euDTuG1+tlwoQJpKamkpSUxMiRI9myZUtYTVFREdnZ2bhcLlwuF9nZ2RQXF4fVbNq0iREjRpCUlERqaioTJ07E5/PV23evNcfe0OQrI8ER6mlSaBIREWlYEQ1NRUVFnHXWWcTFxfHuu++ybt06HnroIVq0aGHVTJ8+nYcffpiZM2eyYsUK3G43559/PqWlpVZNTk4Oc+fOJTc3l0WLFrFnzx6GDx9OILAvWIwePZq8vDzmzZvHvHnzyMvLIzs729oeCAQYNmwYZWVlLFq0iNzcXObMmcOkSZMa5FwcVtzey3P+cuJj9dBeERGRiDARdNttt5mzzz77kNuDwaBxu93mvvvus9ZVVlYal8tlnnrqKWOMMcXFxSYuLs7k5uZaNVu3bjV2u93MmzfPGGPMunXrDGCWLl1q1SxZssQAZv369cYYY9555x1jt9vN1q1brZrXXnvNOJ1O4/F4avV9PB6PAWpdX2v/yzHmrubGfDjVjH9lpel421tm1qIf6/YzREREjlG1/f2OaE/Tm2++Sa9evfjtb39LWloap512Gs8++6y1fcOGDRQUFDB48GBrndPppH///ixevBiAlStX4vf7w2oyMjLIzMy0apYsWYLL5aJ3795WTZ8+fXC5XGE1mZmZZGRkWDVDhgzB6/WGXS6MCGtMU9l+d89pygEREZGGFNHQ9OOPP/Lkk0/SpUsX3nvvPW644QYmTpzIiy++CEBBQQEA6enpYfulp6db2woKCnA4HKSkpBy2Ji0trcbnp6WlhdUc+DkpKSk4HA6r5kBer5eSkpKwpV5Yd8+VWzOCa0yTiIhIw4ro5JbBYJBevXoxdepUAE477TTWrl3Lk08+ydVXX23V2Wy2sP2MMTXWHejAmoPVH03N/qZNm8bdd9992HbUif3vntNAcBERkYiIaE9TmzZt6N69e9i6bt26sWnTJgDcbjdAjZ6ewsJCq1fI7Xbj8/koKio6bM327dtrfP6OHTvCag78nKKiIvx+f40eqGq33347Ho/HWjZv3lyr733E9punKV7zNImIiEREREPTWWedxTfffBO27ttvv6Vjx44AdOrUCbfbzYIFC6ztPp+PhQsX0q9fPwCysrKIi4sLq8nPz2fNmjVWTd++ffF4PCxfvtyqWbZsGR6PJ6xmzZo15OfnWzXz58/H6XSSlZV10PY7nU6aN28ettSL/XqaqkOTeppEREQaVkQvz/3xj3+kX79+TJ06lUsvvZTly5fzzDPP8MwzzwChy2U5OTlMnTqVLl260KVLF6ZOnUpiYiKjR48GwOVyce211zJp0iRatWpFy5YtmTx5Mj169GDQoEFAqPdq6NChjBs3jqeffhqA6667juHDh9O1a1cABg8eTPfu3cnOzuaBBx5g9+7dTJ48mXHjxtVfGKota56mcg0EFxERiZCIhqYzzjiDuXPncvvtt3PPPffQqVMnHnnkEa688kqr5tZbb6WiooLx48dTVFRE7969mT9/PsnJyVbNjBkziI2N5dJLL6WiooKBAwcye/ZsYmJirJpXXnmFiRMnWnfZjRw5kpkzZ1rbY2JiePvttxk/fjxnnXUWCQkJjB49mgcffLABzsTPsOZp2u/ynOZpEhERaVA2Y4yJdCOaipKSElwuFx6Pp257p35aBLOHQasuzD37Df74ry85p0sqL13b++f3FRERkcOq7e93xB+jIrUQ9uw59TSJiIhEgkJTNNjv7jmn7p4TERGJCIWmaHCQnibdPSciItKwFJqiQXVPU8BHQkxoCFql7p4TERFpUApN0aC6pwlIxAvo8pyIiEhDU2iKBrFOsIX+U1WHJl2eExERaVgKTdHAZrPmaoq3VQKhnibNFiEiItJwFJqixd5ZwZ0mFJqMAW+VxjWJiIg0FIWmaLF3XFP83tAE4NVgcBERkQaj0BQt9t5BF1tVQazdBmgwuIiISENSaIoW+83VFK8JLkVERBqcQlO02DumCd++0KQ76ERERBqOQlO02Hv3HP4y4uNC/9nU0yQiItJwFJqixX49TXqUioiISMNTaIoW+z9/zqHQJCIi0tAUmqJF9fPnfGXEx+4dCO7TlAMiIiINRaEpWux/95x6mkRERBqcQlO0CBvTpIHgIiIiDU2hKVo4moX++ss05YCIiEgEKDRFizjdPSciIhJJCk3RwqEZwUVERCJJoSlaxO1391yc7p4TERFpaApN0WK/nibr8lyVeppEREQaikJTtLB6mspJcIT+s1X6FJpEREQaikJTtLB6mso0pklERCQCFJqixX53z2nKARERkYan0BQtqh+jUlVBQmzopXqaREREGo5CU7So7mkCkmw+ACo0pklERKTBKDRFi7gEwAZAi1g/AKWVVRFskIiIyLFFoSla2GxWb1N1aCqu8EeyRSIiIscUhaZosvcOOlds6PKcp8KPMSaSLRIRETlmKDRFk709Tc3sodAUCBr2eHWJTkREpCEoNEWTvXfQOYOVOGND/+mKy3WJTkREpCFENDRNmTIFm80Wtrjdbmu7MYYpU6aQkZFBQkICAwYMYO3atWHH8Hq9TJgwgdTUVJKSkhg5ciRbtmwJqykqKiI7OxuXy4XL5SI7O5vi4uKwmk2bNjFixAiSkpJITU1l4sSJ+Hy+evvuRyVu36NUWiTGAaFLdCIiIlL/It7TdPLJJ5Ofn28tq1evtrZNnz6dhx9+mJkzZ7JixQrcbjfnn38+paWlVk1OTg5z584lNzeXRYsWsWfPHoYPH04gsO92/NGjR5OXl8e8efOYN28eeXl5ZGdnW9sDgQDDhg2jrKyMRYsWkZuby5w5c5g0aVLDnITacuyb4LJFggNQT5OIiEhDiY14A2Jjw3qXqhljeOSRR7jzzju5+OKLAXjhhRdIT0/n1Vdf5frrr8fj8fDcc8/x0ksvMWjQIABefvll2rdvz/vvv8+QIUP4+uuvmTdvHkuXLqV3794APPvss/Tt25dvvvmGrl27Mn/+fNatW8fmzZvJyMgA4KGHHmLs2LHce++9NG/evIHOxs+ofv6cvwzX3p6m4opG1hsmIiLSREW8p+m7774jIyODTp06cfnll/Pjjz8CsGHDBgoKChg8eLBV63Q66d+/P4sXLwZg5cqV+P3+sJqMjAwyMzOtmiVLluByuazABNCnTx9cLldYTWZmphWYAIYMGYLX62XlypWHbLvX66WkpCRsqVdhPU17Q5N6mkRERBpERENT7969efHFF3nvvfd49tlnKSgooF+/fuzatYuCggIA0tPTw/ZJT0+3thUUFOBwOEhJSTlsTVpaWo3PTktLC6s58HNSUlJwOBxWzcFMmzbNGiflcrlo3779EZ6BIxS376G9GtMkIiLSsCIami644AJ+85vf0KNHDwYNGsTbb78NhC7DVbPZbGH7GGNqrDvQgTUHqz+amgPdfvvteDwea9m8efNh2/WLVT9/zldOi8TqMU26PCciItIQIn55bn9JSUn06NGD7777zhrndGBPT2FhodUr5Ha78fl8FBUVHbZm+/btNT5rx44dYTUHfk5RURF+v79GD9T+nE4nzZs3D1vq1X53z7l0eU5ERKRBNarQ5PV6+frrr2nTpg2dOnXC7XazYMECa7vP52PhwoX069cPgKysLOLi4sJq8vPzWbNmjVXTt29fPB4Py5cvt2qWLVuGx+MJq1mzZg35+flWzfz583E6nWRlZdXrdz4i1pimfZfn9CgVERGRhhHRu+cmT57MiBEj6NChA4WFhfz973+npKSEMWPGYLPZyMnJYerUqXTp0oUuXbowdepUEhMTGT16NAAul4trr72WSZMm0apVK1q2bMnkyZOty30A3bp1Y+jQoYwbN46nn34agOuuu47hw4fTtWtXAAYPHkz37t3Jzs7mgQceYPfu3UyePJlx48Y1njvnYL+75/ZNOeBRT5OIiEiDiGho2rJlC1dccQU7d+6kdevW9OnTh6VLl9KxY0cAbr31VioqKhg/fjxFRUX07t2b+fPnk5ycbB1jxowZxMbGcumll1JRUcHAgQOZPXs2MTExVs0rr7zCxIkTrbvsRo4cycyZM63tMTExvP3224wfP56zzjqLhIQERo8ezYMPPthAZ6KW9r97TlMOiIiINCib0RNf60xJSQkulwuPx1M/PVRfvQ7/+T10Opc1g15m+GOLSEt2svzOQXX/WSIiIseI2v5+N6oxTfIzDtrT5Ee5V0REpP4pNEWTsGfPhcY0+aqCVPqDEWyUiIjIsUGhKZpY8zSVkeSIIdYemkNK45pERETqn0JTNNmvp8lms+27RKc76EREROqdQlM02W9ME6AJLkVERBqQQlM02W+eJoyxxjV5dHlORESk3ik0RZPqniYM+CtooZ4mERGRBqPQFE2qxzRB6PlzepSKiIhIg1Foiib2GIiND732lVmPUlFPk4iISP1TaIo2YXM1hXqaNKZJRESk/ik0RRtrrqZyTTkgIiLSgBSaoo3V01SmKQdEREQakEJTtAl7/tzeMU0aCC4iIlLvFJqijTVXU5k15UCJQpOIiEi9U2iKNmE9TdWX5zQQXEREpL4pNEWb/e+e2zvlQJkvgK8qGMFGiYiINH0KTdHGunuujOT4WGy20FuPLtGJiIjUK4WmaLNfT5PdbrPuoNNcTSIiIvVLoSna7DemCdDz50RERBrIUYWmzZs3s2XLFuv98uXLycnJ4Zlnnqmzhskh7Hf3HIArUY9SERERaQhHFZpGjx7NRx99BEBBQQHnn38+y5cv54477uCee+6p0wbKAQ7V06QxTSIiIvXqqELTmjVrOPPMMwH497//TWZmJosXL+bVV19l9uzZddk+OdB+Y5oATTsgIiLSQI4qNPn9fpxOJwDvv/8+I0eOBOCkk04iPz+/7lonNTmahf76QpfnWlgDwdXTJCIiUp+OKjSdfPLJPPXUU3z66acsWLCAoUOHArBt2zZatWpVpw2UAzjCe5o0pklERKRhHFVouv/++3n66acZMGAAV1xxBaeccgoAb775pnXZTupJnMY0iYiIRELs0ew0YMAAdu7cSUlJCSkpKdb66667jsTExDprnByEI/zuOY1pEhERaRhH1dNUUVGB1+u1AtPGjRt55JFH+Oabb0hLS6vTBsoBDuxpStSYJhERkYZwVKHp17/+NS+++CIAxcXF9O7dm4ceeohRo0bx5JNP1mkD5QBWT9PeMU0JGtMkIiLSEI4qNH3xxRecc845APy///f/SE9PZ+PGjbz44ov84x//qNMGygGsnqYyMEaX50RERBrIUYWm8vJykpOTAZg/fz4XX3wxdrudPn36sHHjxjptoByg+u45E4CAzxoIXlJZRSBoItgwERGRpu2oQtMJJ5zAG2+8webNm3nvvfcYPHgwAIWFhTRv3rxOGygHqH6MCoCvzHpgL0CJxjWJiIjUm6MKTX/729+YPHkyxx13HGeeeSZ9+/YFQr1Op512Wp02UA4QEwsxoXFM+MuJjbGT7AzdBKlpB0REROrPUU05cMkll3D22WeTn59vzdEEMHDgQC666KI6a5wcQlwiBHzWHXTNE+Io9VbtHdeUdPh9RURE5KgcVU8TgNvt5rTTTmPbtm1s3boVgDPPPJOTTjrpqI43bdo0bDYbOTk51jpjDFOmTCEjI4OEhAQGDBjA2rVrw/bzer1MmDCB1NRUkpKSGDlyJFu2bAmrKSoqIjs7G5fLhcvlIjs7m+Li4rCaTZs2MWLECJKSkkhNTWXixIn4fI10cPWh5mpST5OIiEi9OarQFAwGueeee3C5XHTs2JEOHTrQokUL/u///o9gMHjEx1uxYgXPPPMMPXv2DFs/ffp0Hn74YWbOnMmKFStwu92cf/75lJaWWjU5OTnMnTuX3NxcFi1axJ49exg+fDiBQMCqGT16NHl5ecybN4958+aRl5dHdna2tT0QCDBs2DDKyspYtGgRubm5zJkzh0mTJh3F2WkAh5qrSdMOiIiI1B9zFP785z+b1q1bmyeeeMJ8+eWXJi8vzzz++OOmdevW5o477jiiY5WWlpouXbqYBQsWmP79+5ubb77ZGGNMMBg0brfb3HfffVZtZWWlcblc5qmnnjLGGFNcXGzi4uJMbm6uVbN161Zjt9vNvHnzjDHGrFu3zgBm6dKlVs2SJUsMYNavX2+MMeadd94xdrvdbN261ap57bXXjNPpNB6Pp9bfxePxGOCI9jkqT51jzF3Njfl2vjHGmPEvrzQdb3vLzFr0Y/1+roiISBNU29/vo+ppeuGFF/jnP//JjTfeSM+ePTnllFMYP348zz77LLNnzz6iY/3hD39g2LBhDBo0KGz9hg0bKCgosO7MA3A6nfTv35/FixcDsHLlSvx+f1hNRkYGmZmZVs2SJUtwuVz07t3bqunTpw8ulyusJjMzk4yMDKtmyJAheL1eVq5ceci2e71eSkpKwpYGUX0HnS90ec6ly3MiIiL17qgGgu/evfugY5dOOukkdu/eXevj5Obm8sUXX7BixYoa2woKCgBIT08PW189kWZ1jcPhCHv+XXVN9f4FBQUHfbRLWlpaWM2Bn5OSkoLD4bBqDmbatGncfffdP/c16171XE3+Ax7aq8tzIiIi9eaoeppOOeUUZs6cWWP9zJkza4xLOpTNmzdz88038/LLLxMfH3/IOpvNFvbeGFNj3YEOrDlY/dHUHOj222/H4/FYy+bNmw/brjqz/6zg6PlzIiIiDeGoepqmT5/OsGHDeP/99+nbty82m43FixezefNm3nnnnVodY+XKlRQWFpKVlWWtCwQCfPLJJ8ycOZNvvvkGCPUCtWnTxqopLCy0eoXcbjc+n4+ioqKw3qbCwkL69etn1Wzfvr3G5+/YsSPsOMuWLQvbXlRUhN/vr9EDtT+n04nT6azV961TjvDLcy2s58810rv9REREmoCj6mnq378/3377LRdddBHFxcXs3r2biy++mLVr1zJr1qxaHWPgwIGsXr2avLw8a+nVqxdXXnkleXl5dO7cGbfbzYIFC6x9fD4fCxcutAJRVlYWcXFxYTX5+fmsWbPGqunbty8ej4fly5dbNcuWLcPj8YTVrFmzhvz8fKtm/vz5OJ3OsFDXaMSFX55zqadJRESk3h1VTxOEBlzfe++9Yeu+/PJLXnjhBZ5//vmf3T85OZnMzMywdUlJSbRq1cpan5OTw9SpU+nSpQtdunRh6tSpJCYmMnr0aABcLhfXXnstkyZNolWrVrRs2ZLJkyfTo0cPa2B5t27dGDp0KOPGjePpp58G4LrrrmP48OF07doVgMGDB9O9e3eys7N54IEH2L17N5MnT2bcuHGN87EwjgMuzyVoILiIiEh9O+rQ1BBuvfVWKioqGD9+PEVFRfTu3Zv58+dbDwsGmDFjBrGxsVx66aVUVFQwcOBAZs+eTUxMjFXzyiuvMHHiROsuu5EjR4aNyYqJieHtt99m/PjxnHXWWSQkJDB69GgefPDBhvuyR6L67rnqgeCJoctzmqdJRESk/tiMMaauDvbll19y+umnh00seSwpKSnB5XLh8Xjqt4fqs0dhwd+g5+Vw8dNsL6mk99QPiLHb+P7eC352oLyIiIjsU9vf76N+jIpEkDWmae88TXsvzwWChj3eqki1SkREpEk7ostzF1988WG3H/g8N6kn1t1zoctz8XExxMfZqfQHKS73kxwfF8HGiYiINE1HFJpcLtfPbr/66qt/UYOkFg64ew5C0w4U+CvxVPhpH6FmiYiINGVHFJpqO52A1LOEvXNSle20VrVIjKOgpFKzgouIiNQTjWmKRqldQn93/whVoQktq8c17dzjjVSrREREmjSFpmiU3AaczcEEYPcPAJyYHpqG4astnki2TEREpMlSaIpGNhuknhh6vSP0uJnTO7YA4ItNRRFqlIiISNOm0BStWp8U+rs3NGV1aAnA2m0eKv3H5jxZIiIi9UmhKVq13tvTtDMUmtq3TCC1mQN/wLB2my7RiYiI1DWFpmh1QE+TzWbjtA6hu+q+2FgcoUaJiIg0XQpN0ap6TNPO7yAYuhx3enVo0rgmERGROqfQFK1adIDYBAh4oegnAE7v0AKAlRuLqMNHCoqIiAgKTdHLHgOpJ4Re771E17NdC2LtNgpLvWwtrohg40RERJoehaZoVj2uae9g8ARHDN3ahJ7O/MWm4gg1SkREpGlSaIpmqV1Df/f2NMG+S3RfbNS4JhERkbqk0BTNWh8kNHUMDQZfpcHgIiIidUqhKZpVh6ad38Legd/Vd9Ct3VaiSS5FRETqkEJTNGvZGeyx4NsDJVsBaJeSQGozJ1VBw+qtmuRSRESkrig0RbOYOGh5fOj1jvVAaJJLjWsSERGpewpN0e4g45qyOmqSSxERkbqm0BTtDjMYfOXGYk1yKSIiUkcUmqLdAc+gA+jR1kWs3cbOPV62FGmSSxERkbqg0BTtqp9Bt2O9dQddfFwMJ2dUT3KpS3QiIiJ1QaEp2qV2AWxQWQxlO6zVp1U/vFeDwUVEROqEQlO0i0uAlI6h1wcb16SeJhERkTqh0NQUWOOa1lurendqic0Ga7aWsHFXWYQaJiIi0nQoNDUF1eOadn5rrUpvHs85XVoD8P9WbolEq0RERJoUhaam4CA9TQCX9moHhEJTIKipB0RERH4Jhaam4CBzNQEM6paOKyGOfE8ln32/MwINExERaToUmpqC6stze7ZDxb6B3/FxMYw6NQOAf3++ORItExERaTIUmpqC+OaQHApH7Pg2bNNve7UHYP7a7RSX+xq6ZSIiIk2GQlNTkX5y6O/mpWGrM9u66NamOb5AkDe/3BaBhomIiDQNCk1NRdehob/r/ltjU/WAcF2iExEROXoRDU1PPvkkPXv2pHnz5jRv3py+ffvy7rvvWtuNMUyZMoWMjAwSEhIYMGAAa9euDTuG1+tlwoQJpKamkpSUxMiRI9myJfwW+6KiIrKzs3G5XLhcLrKzsykuLg6r2bRpEyNGjCApKYnU1FQmTpyIzxdFl7O6jQRssHUlFG8K2zTq1LY4Yuys2VrC2m2eyLRPREQkykU0NLVr14777ruPzz//nM8//5xf/epX/PrXv7aC0fTp03n44YeZOXMmK1aswO12c/7551NaWmodIycnh7lz55Kbm8uiRYvYs2cPw4cPJxAIWDWjR48mLy+PefPmMW/ePPLy8sjOzra2BwIBhg0bRllZGYsWLSI3N5c5c+YwadKkhjsZv1SzNOh4Vuj1ujfDNqUkORjUPQ2A1z/XnE0iIiJHxTQyKSkp5p///KcJBoPG7Xab++67z9pWWVlpXC6Xeeqpp4wxxhQXF5u4uDiTm5tr1WzdutXY7XYzb948Y4wx69atM4BZunSpVbNkyRIDmPXr1xtjjHnnnXeM3W43W7dutWpee+0143Q6jcfjqXXbPR6PAY5onzq17Blj7mpuzLMDa2z6cP120/G2t8ypd79nKv1VEWiciIhI41Tb3+9GM6YpEAiQm5tLWVkZffv2ZcOGDRQUFDB48GCrxul00r9/fxYvXgzAypUr8fv9YTUZGRlkZmZaNUuWLMHlctG7d2+rpk+fPrhcrrCazMxMMjIyrJohQ4bg9XpZuXLlIdvs9XopKSkJWyKq2wjABltWgCe8R+ncLq1xN4+nqNzPe2u3R6Z9IiIiUSzioWn16tU0a9YMp9PJDTfcwNy5c+nevTsFBQUApKenh9Wnp6db2woKCnA4HKSkpBy2Ji0trcbnpqWlhdUc+DkpKSk4HA6r5mCmTZtmjZNyuVy0b9/+CL99HUt2Q4e+odcHXKKLsdu4/MxQ+2Ys+BZfVbChWyciIhLVIh6aunbtSl5eHkuXLuXGG29kzJgxrFu3ztpus9nC6o0xNdYd6MCag9UfTc2Bbr/9djwej7Vs3twI7k47eVTo77o3amz6/TmdSW3mYMPOMl5ZtrFBmyUiIhLtIh6aHA4HJ5xwAr169WLatGmccsopPProo7jdboAaPT2FhYVWr5Db7cbn81FUVHTYmu3ba16O2rFjR1jNgZ9TVFSE3++v0QO1P6fTad35V71EXLeRob+bl0FJ+LxMzZyx/PH80Ozhj37wHZ4Kf0O3TkREJGpFPDQdyBiD1+ulU6dOuN1uFixYYG3z+XwsXLiQfv36AZCVlUVcXFxYTX5+PmvWrLFq+vbti8fjYfny5VbNsmXL8Hg8YTVr1qwhPz/fqpk/fz5Op5OsrKx6/b51rnkbaN8n9PqAS3QAl/VqT5e0ZhSX+3n8o+8buHEiIiLRK6Kh6Y477uDTTz/lp59+YvXq1dx55518/PHHXHnlldhsNnJycpg6dSpz585lzZo1jB07lsTEREaPHg2Ay+Xi2muvZdKkSXzwwQesWrWKq666ih49ejBo0CAAunXrxtChQxk3bhxLly5l6dKljBs3juHDh9O1a+hBt4MHD6Z79+5kZ2ezatUqPvjgAyZPnsy4ceMaR+/RkbIu0dWc6DI2xs4dw7oBMPuzn9i8u7wBGyYiIhK9Ihqatm/fTnZ2Nl27dmXgwIEsW7aMefPmcf755wNw6623kpOTw/jx4+nVqxdbt25l/vz5JCcnW8eYMWMGo0aN4tJLL+Wss84iMTGR//3vf8TExFg1r7zyCj169GDw4MEMHjyYnj178tJLL1nbY2JiePvtt4mPj+ess87i0ksvZdSoUTz44IMNdzLqUvUluk1LoLTmQPYBJ7bmnC6p+AJB7pu3voEbJyIiEp1sxhgT6UY0FSUlJbhcLjweT+R7qP55PmxZDhc8AL2vq7F53bYShj32KcbAnBv7kdUx5SAHERERafpq+/vd6MY0SR2pvkS39j8H3dw9ozm/zQo9k+7/3lpHIKjsLCIicjgKTU1V91Fgjw1dotvwyUFLJg3uSpIjhrzNxTz24XcN2z4REZEoo9DUVLnaQtbvQq8X/A2CNSezTG8ez98vygRCUxAs/n5nQ7ZQREQkqig0NWX9bwNHM9i2CtbNPWjJRae149Je7TAGbv5XHjtKvQ3cSBERkeig0NSUNWsN/SaGXn9wD1T5Dlp298hMTkxvxo5SL3/8V57GN4mIiByEQlNT1/cPkJQGRT/B588ftCTBEcPjo08nIS6GRd/v5AlNeikiIlKDQlNT52wG590eev3JdKgsOWhZl/Rk7vn1yQDMeP9bPtP4JhERkTAKTceC066GVl2gfBd89ughy37bqz2/Ob0dQQPjXvycz3/a3YCNFBERadwUmo4FMbEw6K7Q6yWP13iQ7/7uvSiTc7qkUu4LMHbWCr7YVHTIWhERkWOJQtOx4qTh0L43VFXAf2866BQEAPFxMTyT3Yu+nVuxx1vFmOeW89WW4oZtq4iISCOk0HSssNlg+AyIjYcfPoBFDx+yNMERw3Nje3HmcS0p9VZx1T+XsWarpwEbKyIi0vgoNB1L0k+GCx8Ivf7oXvjps0OWJjpief53Z3B6hxaUVFZx1XPLWL5BY5xEROTYpdB0rDktG3peDiYI/+8a2LPjkKXNnLHMvuZMTuvQguJyP1f9cxlvrNragI0VERFpPBSajjU2Gwx/GFK7wp4C+M84CAYOWd48Po5Xf9+HoSe78QWC5Pwrj0fe/xZjNAGmiIgcWxSajkWOJLj0BYhLhB8/gk8ePGx5giOGJ648nevP7QzAI+9/xy3//hJv1aHDloiISFOj0HSsSusGwx4Kvf54Kix54rDldruN2y/sxrSLexBjtzF31VYufWoJG3eVNUBjRUREIk+h6Vh26mg46+bQ6/duh08e+NldrjizA7N/dwauhDi+3OJh2D8W8d88jXMSEZGmT6HpWDfobhhwR+j1h3+H96fAz4xXOqdLa965+RzOOC6FPd4qbs7N40+vf0m5r6r+2ysiIhIhCk3HOpsNBtwGg/8eer9oBrx76yEnv6zWtkUCr43rw8SBXbDb4PWVWxj+j0Us/XFXAzRaRESk4Sk0SUi/CaHJL7HB8mfg5YuhaONhd4mNsXPL+Sfy6rg+uJvH8+POMi5/ZimT/v0lu/Z4G6bdIiIiDUShSfbpdQ1c/Exo1vAfP4In+sLSJw87JQFAn86teC/nXK7s3QGbDeZ8sYVfPbSQ15ZvIhjU1AQiItI02Iwm3KkzJSUluFwuPB4PzZs3j3Rzjt7O7+F/E2Hj3hnD250BI/4B6d1/dtdVm4q4c+4a1uWXAHByRnNyBp3IoG5p2Gy2+my1iIjIUant77dCUx1qMqEJQmOavpgNC+4Cbwlgg64XQt8/QMd+obFQh1AVCPLCko3MWPAte7yhweE92rrIGdSFX52k8CQiIo2LQlMENKnQVK1kW2hg+Nf/27euzSnQZzxk/gZi4g656+4yH89++iMvLP6Jcl/oEl/Pdi6uPbsTF/ZoQ1yMrg6LiEjkKTRFQJMMTdV2fBMa3/RlLlRVhNalZ8KoJ0Ih6jB27fHyzKc/8uLijVT4Q+EpvbmT7D4dueLMDrRq5qzv1ouIiBySQlMENOnQVK18N3z+PCx5HCp2gz0WzpkE50yGWMdhd925x8vLSzfy8tJN7Nx7d50j1s7Qk92MPCWDc05MxRkb0xDfQkRExKLQFAHHRGiqtmcHvH0LfP1m6H16j729Tj1/dldfVZC3V29j1mc/8dUWj7U+OT6WoSe7GX5KBn06t1SAEhGRBqHQFAHHVGiC0Mzha+bAO38K9Tphg8794bRsOGkYxCX8zO6GL7d4eDNvG299tY3C0n1zOyXExdD3+Fb0P7E1557YmuNaJWoAuYiI1AuFpgg45kJTtT2FoeC07o196+JdkHlJaLB4+zMPO2AcIBA0rPhpN299tY331m5nR2n45JjtUhLo27kVfY8PLW1chw9kIiIitaXQFAHHbGiqVrQR8l4NLZ5N+9Y7XXD8edBlMBz/K0h2H3bKAmMMX+eX8sl3O1j4zQ4+37gbfyD8n2mn1CTOOC6FXh1b0uu4FDqlJqknSkREjopCUwQc86GpWjAIP30Cea/B9wug/IDn0Tld0KoztDoBWh4fGgfVsR8kpBz0cGXeKj7fWMTiH3ay5IddrNnq4cCJxlslOTi1fQu6upM5qU1zTnIn0yk1SdMaiIjIz1JoigCFpoMIBmDbKvhufmjZlgcc7J+cDdyZ0PFs6NAHWnSAZunQLK3GpT1PhZ/Pf9rN5xuL+Pyn3Xy5xYOvquYDhh0xdjqlJnF8WhIntG7G8WnN6JzajPYtE3AlxKlnSkREAIWmiFBoqgV/BezeALt/gF3fhx7ZsnkZ7Pru0PsktoIWHSGtO6R127cktwGbDW9VgDVbS1i7zcP6glLW55fwTUEpZb5DPzMv2RlL25QE2qUk0i4lYb8lkbYtEmiRqFAlInKsiIrQNG3aNP7zn/+wfv16EhIS6NevH/fffz9du3a1aowx3H333TzzzDMUFRXRu3dvHn/8cU4++WSrxuv1MnnyZF577TUqKioYOHAgTzzxBO3atbNqioqKmDhxIm++GbpFfuTIkTz22GO0aNHCqtm0aRN/+MMf+PDDD0lISGD06NE8+OCDOByHn3+omkLTL1C6HTYugp8+g21fhN6XFUKw6tD7xCVCynF7l07QPAPim4OzOUFHMjv8TjaUxfFdSSzri218u6OSDTvLrTmiDscZa6eNKx63K542rgTSm8fTxhVv/XW74klJdOCI1eU/EZFoFxWhaejQoVx++eWcccYZVFVVceedd7J69WrWrVtHUlISAPfffz/33nsvs2fP5sQTT+Tvf/87n3zyCd988w3JyckA3Hjjjfzvf/9j9uzZtGrVikmTJrF7925WrlxJTExorp8LLriALVu28MwzzwBw3XXXcdxxx/G//4UeDxIIBDj11FNp3bo1Dz30ELt27WLMmDFcfPHFPPbYY7X6PgpNdSwYDE1lUFoQ6pkq/BoK14X+7voBzKF7kg7K2RziWxB0JuONbUaZLQmPScRT5aDIH8sObyyFlTEUemPZbZIpIpndJrTsIYFKHBjCQ1KyM5aUJAcpSQ5Skxy0TnaS2sxJ62Rn2OvUZg6aOWPVeyUi0ghFRWg60I4dO0hLS2PhwoWce+65GGPIyMggJyeH2267DQj1KqWnp3P//fdz/fXX4/F4aN26NS+99BKXXXYZANu2baN9+/a88847DBkyhK+//pru3buzdOlSevfuDcDSpUvp27cv69evp2vXrrz77rsMHz6czZs3k5GRAUBubi5jx46lsLCwViFIoakBVfnAsxmKNoQu9xX9BHu2Q2UJeEtDDxmuLIHK4r0PHK4bfmKpwEmlicNPDAFjx08sAexU4qCceMpMPGXEU2kcJNoqaU45zW3luGzlxNih3N6cilgXXoeLKkcLvPGt8SelE0hqA8luHEkuku0+mtkqSKKcZnhJaJ5CUqt22JLd4Eiqs+8jIiK1//2ObcA2/SyPJzQ7dMuWLQHYsGEDBQUFDB482KpxOp3079+fxYsXc/3117Ny5Ur8fn9YTUZGBpmZmSxevJghQ4awZMkSXC6XFZgA+vTpg8vlYvHixXTt2pUlS5aQmZlpBSaAIUOG4PV6WblyJeedd16N9nq9XrzefZd6Skrq7sdZfkasA1odH1p+TsAPlR6oKIKKYvB69gYqTyhQ+crBX7b3b0VoXfnu0F1/5TtDr/cOXo+jijiqaF7dYXSkHUcGCORDAPj5q4QHVUYiJTEtqLI7CNodBO1OgjEOHPhJCJYTHyzDESgjJujDl9Aaf7O2BJPbYnO1I6ZZK+KcCcQ5E7DHJYA9BnxloXNRfU6CfohxhgbgxzhCS6wTYuND5z02PrQ4moGzWSjEOZJC7x1Jocum6lETkSao0YQmYwy33HILZ599NpmZmQAUFBQAkJ6eHlabnp7Oxo0brRqHw0FKSkqNmur9CwoKSEtLq/GZaWlpYTUHfk5KSgoOh8OqOdC0adO4++67j/SrSkOLiYOk1NByNIJB8JdDVWUoVPkrQq+DVaG7A4P+UDCr8oKvNBRCvHtC+ziTId6FN7YZRYFESip9+Ep34d+zi2BZKJg5KnaQ6C2kma8Ql38nDlNJhS2BchIoNQmUGQdJphy3rYhEm5ckykkKlIeC189I2LOZhD2b4eD/hOuFwRYKTnEJoXfGACY0g3yMAxyJe7fvrakOZdV/bXYwwf0WEwpnzuahSVOdzUPhbP8QZx3DGVpXHfbssaH//vY4iIkNHav6uMG9JzDWuW9f+97Lr9V1AT8EfHv/u5fv+xvrhKS00L8pux73I3KsaDSh6aabbuKrr75i0aJFNbYdOA7EGPOzY0MOrDlY/dHU7O/222/nlltusd6XlJTQvn37w7ZLopDdvvdHu9lRH8IJuPcuP8sYkmw2koDWe1dV+gMUl/nYWLyL8l3bqPRsp8pXSZWvgoCvkiqfl/JADMXBeIqqnOwOxFPigwTvDly+Alr4d9AqUEhicA9O/NYSZ6uizMRTQhKlJoFSEvERSxwBHPiJowoHVThsfpxU7d3PR7zNRyJeEqkkyVZJEpUk4sVuM9gwoZ47f9nBv98hVjcKMY5QYAr6a1dvs0Pi3kBeHfyqA5o9bm9gi90X4AJe8FeGQndVZSiYxSXu66FzJAK20Hg9EwwFdhPYG86r9gV1e0wocMbGh/7GJYQCZXwLSGgR+utoFt5baI8JBT5f2b4FA3FJ+4KsoxnExUNsQuj7xCWE2lm8OXQ5vHgTlOZDQstQL2/L40PTg/zMw7pFmopGEZomTJjAm2++ySeffBJ2x5vbHfqJKSgooE2bNtb6wsJCq1fI7Xbj8/koKioK620qLCykX79+Vs327dtrfO6OHTvCjrNs2bKw7UVFRfj9/ho9UNWcTidOp/NovrLIoR0kpMfHxeBukYC7RTs4rt1BdqqdYNBQWRWg3BegwhegzFdFjDdArK8KpzdAoq+KMm8V5b4Apb4A5b7Qa38gSFXA4A8aqgJBfFVByn0Byv0ByvfWe/1VGH8FMVXlOE0FCfgw2Ajudw0zjgCJVFqhKwEvDqqIs1XhwI+DKmwYgtgw2Aliw4YhiUqSbeUkU05zWwWJVIbqbaEgV72v0xb6Wx34YgkSSxUxtloO3Qz4DrraYMNvj8cfk0CVzUms8ZLoL8JmgqG7PMsKj/q/SdSzxYRm+a/uOawOc8FA+GXvYBUktgwFzMRUSGodCpdVvlAwC/hCNY5m+4JfQotQqLPbQ59js4eW6gAZ8IV6A2Od4GofCnDJbULHFakHEf2XZYxhwoQJzJ07l48//phOnTqFbe/UqRNut5sFCxZw2mmnAeDz+Vi4cCH3338/AFlZWcTFxbFgwQIuvfRSAPLz81mzZg3Tp08HoG/fvng8HpYvX86ZZ54JwLJly/B4PFaw6tu3L/feey/5+flWQJs/fz5Op5OsrKz6PxkiDcBut5HoiCXRUb//0/cHglT4A1T6AlT4Q0u5L4C/KkhV0OwLYYHw8FXmC+CrChIMBPFXBfHvDWg79v71Vf894LW3xvtA2KzxNoLEEcBgI7A3jIUGpBniCODEFwpd+DFAFbFUYaeKGPzE4iWOAwewxRCgJaW0thXT0la6N6gFiCVALFU4bFV7XweII0AMAfzEUomDSuPASxxBbKEeO1soQCbuHegWwI7Bhm1vWDD22FBP0d6/cbYgTuPDSWhJwEtzWxnNTRnJlJFsSnEYH7H4iTVVxJoq7ATw25147Qn47Qn47Algs+EMVuIIVuAIVhIXrCA26CXWhPe0+WObUZGYQUViBt4EN05fEYllG0ncs4mYqnIo2Vq7fxil247631St2WND048kpu4NX3t74JqlQ8ap0DYrNGmuyFGI6N1z48eP59VXX+W///1v2NxMLpeLhITQA1nvv/9+pk2bxqxZs+jSpQtTp07l448/rjHlwFtvvcXs2bNp2bIlkydPZteuXTWmHNi2bRtPP/00EJpyoGPHjjWmHEhPT+eBBx5g9+7djB07llGjRmnKAZEoVBUI4g+YUIgKhMJYVcBQFQytDwQN3qoAZd5Qj9oeb4Ayb1Uo7PkDVPqDVPoD+AJB7Daw22zYbTZsNqywF+qtC4VDAGyhaGWzQdCEHkRdFQgFxapA6PO8VaHjevcGvIAxNJ57mEPsBEOXYfFRRSylJB6i0tCaYtrYdhO/97Jtwt4gV0VM6E5THJQbJ0HspNhKaUkpafYS0mJKibMF8OLAhwO/LZYgMbSwV9IyppwUexkuynDa/MQQxE6QmL19kNhiCdpjMfY4jD0Wp6nE5S2gmbeAGHOYud2qudpD29OhfW/o0BfcPdU7dYyLiikHDjVWaNasWYwdOxbYN7nl008/HTa5ZfVgcYDKykr+9Kc/8eqrr4ZNbrn/+KLdu3fXmNxy5syZNSa3HD9+fI3JLWt7CU6hSUSOhjGhEFcV3Ps3YPAFgqGAV2XwB0O9bv4qgy8Q6kUzJrRf0EDQGKunrTqMVQVCgSwQPGAxhmDQEAhCIFhdE3rtDxi8VUG8/gCVVaHg6KsKYjAEg6HPCRpjhUB/IGgdt7ojLtR/FwqWlf4glb7QsQ586HZ9sBOkNcW0te0kxVaKi7LQdB+UcVzsTrJiN9AusBn7gY9ycjQLBaiOfUOPcmp7euiSnxwzoiI0NTUKTSIiB1cVCF1C9fqDVm/bvl620M9QIAjlvirKvAH2eEPj67x7e+MCe3vsqsOlb+/l2+pwFroEHBpfV+4N4KnwU1Tuo7jcjy+w79mUzSinh30Dp9p+oJf9G86M+YZkysMbGxsP7c4IPUj8pGHQ5pSGO1ESEQpNEaDQJCLSuBhjKPcFyPdU8H3hHr7bvofvCvfw7fZSvt1eCiZIV9tmzrSv50z71/SJ+YZWeMIP0mUI9L8V2vWKzJeQeqfQFAEKTSIi0aPMW8WXW4pZtamYVZuKWL5hNyWVfo63beNM+3rOjVnNEPvn2NnbU3X8r6D/bdChT2QbLnVOoSkCFJpERKJXVSDIyo1FfLi+kA/WF/J94R462gr4Q8x/uTjmU2JtofBkOp+H7Vd/Uc9TE6LQFAEKTSIiTcdPO8t4I28rc77YginayPiY//LbmE+Is4XuljRdhmA7747QVAYS1RSaIkChSUSk6QkGDSt+2s2cL7aw8ss8rjdz+E3MJ9akqcGTL8Z+4YOQ1CrCLZWjpdAUAQpNIiJN2649Xp5btIGFS5YwLvhvRtqXYLcZfInpOC55BjoPiHQT5SgoNEWAQpOIyLHBU+5n9uKfWLzoA6YGH+F4ez5BbPh6TyD+/L/qeXxRRqEpAhSaRESOLcXlPh58axXdv7qP0bEfhta1OBlX9svYWnWOcOuktmr7+21vwDaJiIg0KS0SHfz90t50vuaf/C3+zxSZZrQoXkvZE/2p/GFRpJsndUyhSURE5Bfq07kVd06+ldfPyOWrYGeaBUqwv/RrCj97KdJNkzqk0CQiIlIHnLExXDf8HPxXv8WHtt44qCJtwU388PpfaXRPZZajotAkIiJSh7JOaEtmzhu8kXgJAMev/QfrnriCoN8X4ZbJL6XQJCIiUsfSXIlceMuzvNnhNqqMne473mXtoxfh91ZEumnyCyg0iYiI1ANHrJ2R19zBkt6P4zVx9NiziK9njKBsT2mkmyZHSaFJRESkHp1z4Wi+/tU/KTdOelau4PtHh7G7qCjSzZKjoNAkIiJSz07tP4rNw16ijHhO8X/J1pkXsLVge6SbJUdIoUlERKQBdD1zCLsv/helJNIj8DU7nx7Jlu07I90sOQIKTSIiIg2kfc8BVI5+g1KSOMWsZ9PTl7Kp0BPpZkktKTSJiIg0oNYn9qbqslwqcdAvuJKvn7qKTTv3RLpZUgsKTSIiIg0spdu5VI6aRRUxDAl+wrInx7FRwanRU2gSERGJgBanDqfswscA+G3gHeY/OYnNu8sj3Co5HIUmERGRCHGdeSWl590LwLhALq8/NYXCksoIt0oORaFJREQkgpL738SePpMAyPE+w9NPzaC4XI9caYwUmkRERCKs2ZC/UnryVdhthlvLHuSBp59jj7cq0s2SAyg0iYiIRJrNRvJv/sGeTkNx2qq4rfhu/u+f/6LSH4h0y2Q/Ck0iIiKNgT2GZqNfYI+7N81tFUwqvIMpL7yDPxCMdMtkL4UmERGRxiIunmZj/k1Zi66k2Yq5btNk7s79hGDQRLplgkKTiIhI45LQgqRr/ktFYls62wu45Js/cu8bn2OMglOkKTSJiIg0Ns3bkPC7N/DFuTjV/iNnrZrMI++ti3SrjnkKTSIiIo1R6xNxXP3/qLLH86uYPNot+jPPLvwh0q06pik0iYiINFbtzyT2shcIEsNvYz/Bu+BucpdvinSrjlkKTSIiIo1Z16HYRswA4KbY//Ltm9P535fbItyoY1NEQ9Mnn3zCiBEjyMjIwGaz8cYbb4RtN8YwZcoUMjIySEhIYMCAAaxduzasxuv1MmHCBFJTU0lKSmLkyJFs2bIlrKaoqIjs7GxcLhcul4vs7GyKi4vDajZt2sSIESNISkoiNTWViRMn4vNpRlYREYk8W9YYzHl3AvC32Jf47PUZfLh+e4RbdeyJaGgqKyvjlFNOYebMmQfdPn36dB5++GFmzpzJihUrcLvdnH/++ZSWllo1OTk5zJ07l9zcXBYtWsSePXsYPnw4gcC+CcFGjx5NXl4e8+bNY968eeTl5ZGdnW1tDwQCDBs2jLKyMhYtWkRubi5z5sxh0qRJ9fflRUREjoDt3D9h+twEwL0xz/LfV55gyQ+7ItyqY4xpJAAzd+5c630wGDRut9vcd9991rrKykrjcrnMU089ZYwxpri42MTFxZnc3FyrZuvWrcZut5t58+YZY4xZt26dAczSpUutmiVLlhjArF+/3hhjzDvvvGPsdrvZunWrVfPaa68Zp9NpPB5Prb+Dx+MxwBHtIyIiUmvBoAm8McGYu5ob799SzPV/nWpWbSqKdKuiXm1/vxvtmKYNGzZQUFDA4MGDrXVOp5P+/fuzePFiAFauXInf7w+rycjIIDMz06pZsmQJLpeL3r17WzV9+vTB5XKF1WRmZpKRkWHVDBkyBK/Xy8qVK+v1e4qIiNSazYZ9xAwC3S/GYQvwiO0h/vHcLNZs9US6ZceERhuaCgoKAEhPTw9bn56ebm0rKCjA4XCQkpJy2Jq0tLQax09LSwurOfBzUlJScDgcVs3BeL1eSkpKwhYREZF6ZY8h5jfPUHXCUOJtfh4193PvP19l7TYFp/rWaENTNZvNFvbeGFNj3YEOrDlY/dHUHGjatGnW4HKXy0X79u0P2y4REZE6ERNH7GUvUNXhbJJtFcwM3stfnv0PX+fr/3mvT402NLndboAaPT2FhYVWr5Db7cbn81FUVHTYmu3ba95hsGPHjrCaAz+nqKgIv99fowdqf7fffjsej8daNm/efITfUkRE5CjFxRM7+jUC7lNoZStlZvD/mPTsW6wvUHCqL402NHXq1Am3282CBQusdT6fj4ULF9KvXz8AsrKyiIuLC6vJz89nzZo1Vk3fvn3xeDwsX77cqlm2bBkejyesZs2aNeTn51s18+fPx+l0kpWVdcg2Op1OmjdvHraIiIg0mPjmxGT/h0DLE2hr28VjVfcw/pn5Ck71JKKhac+ePeTl5ZGXlweEBn/n5eWxadMmbDYbOTk5TJ06lblz57JmzRrGjh1LYmIio0ePBsDlcnHttdcyadIkPvjgA1atWsVVV11Fjx49GDRoEADdunVj6NChjBs3jqVLl7J06VLGjRvH8OHD6dq1KwCDBw+me/fuZGdns2rVKj744AMmT57MuHHjFIRERKRxS0olZsx/CSa35Xh7Po9W/R/XPv0hq7dojFOda4A7+Q7po48+MkCNZcyYMcaY0LQDd911l3G73cbpdJpzzz3XrF69OuwYFRUV5qabbjItW7Y0CQkJZvjw4WbTpk1hNbt27TJXXnmlSU5ONsnJyebKK680RUVFYTUbN240w4YNMwkJCaZly5bmpptuMpWVlUf0fTTlgIiIRMyOb03g/s7G3NXcfPHX003fv80xn/+0K9Ktigq1/f22GWNMBDNbk1JSUoLL5cLj8aiHSkREGl7+l5gXfo2tsoivgp24nr/w0NUD6HdCaqRb1qjV9ve70Y5pEhERkSPU5hRsY/+HSWhFT/sGnudubpn9AR+tL4x0y5oEhSYREZGmxN0D2+/exiSl0c2+iRftd3P7i++Tu3xTpFsW9RSaREREmpq0bth+9w4muQ0n2rfyauzdPDV3PtPe+ZpgUKNyjpZCk4iISFOU2iUUnFzt6Wwv4A3H31i96E1ufGUl5b6qSLcuKik0iYiINFUtO2P7/QfQ7gxa2Mp4Me4+Wq9/mcueXkqBpzLSrYs6Ck0iIiJNWXI6jHkLel5GrC3I3+Nmccn2R/j1Pz7ms+93Rrp1UUWhSUREpKmLi4eLnoaBd2GwMSZ2Af/w38Wk597lHx98p3FOtaTQJCIiciyw2eCcW7Bd/grG0Yze9vW87bidzz94nbGzV7C7zBfpFjZ6Ck0iIiLHkpOGYbv+E3D3oJWtlBcd99P7x8cY8cjHfPyN5nM6HIUmERGRY02r4+Ha9+GM3wPwh9g3edR7J9Nnv86t/+9LPBX+CDewcVJoEhERORbFxcOwh+CSWRhHM3rZv+Utx51k5f2N0Q+/oVnED0KhSURE5FiWeTG28Uvg5Iux2wyXxX7Mv31/4IuXbueWV5awtbgi0i1sNPTA3jqkB/aKiEhU27yc4LzbsW/9HIAtJpX7glfT6ezLuGHACSQ5YyPcwPqhB/aKiIjIkWl/Jvbfvw+XPI+vWVva2XYyM+Zhzlj0e8Y88Ar//nwzVYFgpFsZMeppqkPqaRIRkSbDV4759CHMZ49iD/rxmRhmBYbybvPfcsV5WVx0WjscsU2j76W2v98KTXVIoUlERJqcXT8QePfPxHw/HwCviWNu4CzeSryIIecN4Le92hMfFxPZNv5CCk0RoNAkIiJN1rfvEfj4fmK2rbRWfRw4hTmxF9ImaxiX9+5E59bNItjAo6fQFAEKTSIi0qQZA5uXE/jsH9i/eRsboQixzbTk/wXO5Ye2F3H+WWcyqFt6VPU+KTRFgEKTiIgcM3b/SHDZM1Steg2Hr9ha/VngZD61n4Gty0D6ndmHvsenEhvTuMc+KTRFgEKTiIgcc6q8sP5tKpfPwrnpU6v3CUJTFiyzn463Y38yTjmfM08+nkRH45u2QKEpAhSaRETkmFa0keDa/1K6dh5JBcuJNfsexxI0NtZxHBuTs4g5vj9te/Sn63HtG8UdeApNEaDQJCIispevjKofP6Xgi7dwbPyUNO9PYZuDxsb3tGVjYiaV6afT7LgsWnfoynFt29CsgSfRVGiKAIUmERGRgzMl+RR+tYDite+TsmM5aVX5B63bbZqRb3fjcbalMqkNweS2xKa0JzG1A83dx3Fc+47E1/ElPoWmCFBoEhERqR1Tup3Crz+l+NvPcOavpGX5TzQ3np/d74dR/+P4U8+t07bU9ve78Y3GEhERkSbPlpxO+pmXkH7mJftWekspLfiBnZu+YU/BdwQ9W4kt3UZiRT4ufyEtTDEtMzpHrM0KTSIiItI4OJNJ7ngqyR1PPfj2Kh8pMXEN2qT9KTSJiIhIdIh1RPTjI3+fn4iIiEgUUGgSERERqQWFJhEREZFaUGgSERERqQWFJhEREZFaUGgSERERqQWFpgM88cQTdOrUifj4eLKysvj0008j3SQRERFpBBSa9vOvf/2LnJwc7rzzTlatWsU555zDBRdcwKZNmyLdNBEREYkwPXtuP7179+b000/nySeftNZ169aNUaNGMW3atJ/dX8+eExERiT61/f1WT9NePp+PlStXMnjw4LD1gwcPZvHixQfdx+v1UlJSEraIiIhI06TQtNfOnTsJBAKkp6eHrU9PT6egoOCg+0ybNg2Xy2Ut7du3b4imioiISAQoNB3AZrOFvTfG1FhX7fbbb8fj8VjL5s2bG6KJIiIiEgF6YO9eqampxMTE1OhVKiwsrNH7VM3pdOJ0OhuieSIiIhJhCk17ORwOsrKyWLBgARdddJG1fsGCBfz617+u1TGqx9RrbJOIiEj0qP7d/rl74xSa9nPLLbeQnZ1Nr1696Nu3L8888wybNm3ihhtuqNX+paWlABrbJCIiEoVKS0txuVyH3K7QtJ/LLruMXbt2cc8995Cfn09mZibvvPMOHTt2rNX+GRkZbN68meTk5EOOgzoaJSUltG/fns2bN2sqg3qmc91wdK4bjs51w9L5bjh1da6NMZSWlpKRkXHYOs3TFAU0/1PD0bluODrXDUfnumHpfDechj7XuntOREREpBYUmkRERERqQaEpCjidTu666y5Nb9AAdK4bjs51w9G5blg63w2noc+1xjSJiIiI1IJ6mkRERERqQaFJREREpBYUmkRERERqQaFJREREpBYUmqLAE088QadOnYiPjycrK4tPP/000k2KatOmTeOMM84gOTmZtLQ0Ro0axTfffBNWY4xhypQpZGRkkJCQwIABA1i7dm2EWtx0TJs2DZvNRk5OjrVO57pubd26lauuuopWrVqRmJjIqaeeysqVK63tOt91o6qqir/85S906tSJhIQEOnfuzD333EMwGLRqdK6PzieffMKIESPIyMjAZrPxxhtvhG2vzXn1er1MmDCB1NRUkpKSGDlyJFu2bPnljTPSqOXm5pq4uDjz7LPPmnXr1pmbb77ZJCUlmY0bN0a6aVFryJAhZtasWWbNmjUmLy/PDBs2zHTo0MHs2bPHqrnvvvtMcnKymTNnjlm9erW57LLLTJs2bUxJSUkEWx7dli9fbo477jjTs2dPc/PNN1vrda7rzu7du03Hjh3N2LFjzbJly8yGDRvM+++/b77//nurRue7bvz97383rVq1Mm+99ZbZsGGDef31102zZs3MI488YtXoXB+dd955x9x5551mzpw5BjBz584N216b83rDDTeYtm3bmgULFpgvvvjCnHfeeeaUU04xVVVVv6htCk2N3JlnnmluuOGGsHUnnXSS+fOf/xyhFjU9hYWFBjALFy40xhgTDAaN2+029913n1VTWVlpXC6XeeqppyLVzKhWWlpqunTpYhYsWGD69+9vhSad67p12223mbPPPvuQ23W+686wYcPMNddcE7bu4osvNldddZUxRue6rhwYmmpzXouLi01cXJzJzc21arZu3WrsdruZN2/eL2qPLs81Yj6fj5UrVzJ48OCw9YMHD2bx4sURalXT4/F4AGjZsiUAGzZsoKCgIOy8O51O+vfvr/N+lP7whz8wbNgwBg0aFLZe57puvfnmm/Tq1Yvf/va3pKWlcdppp/Hss89a23W+687ZZ5/NBx98wLfffgvAl19+yaJFi7jwwgsBnev6UpvzunLlSvx+f1hNRkYGmZmZv/jcx/6ivaVe7dy5k0AgQHp6etj69PR0CgoKItSqpsUYwy233MLZZ59NZmYmgHVuD3beN27c2OBtjHa5ubl88cUXrFixosY2neu69eOPP/Lkk09yyy23cMcdd7B8+XImTpyI0+nk6quv1vmuQ7fddhsej4eTTjqJmJgYAoEA9957L1dccQWgf9v1pTbntaCgAIfDQUpKSo2aX/rbqdAUBWw2W9h7Y0yNdXJ0brrpJr766isWLVpUY5vO+y+3efNmbr75ZubPn098fPwh63Su60YwGKRXr15MnToVgNNOO421a9fy5JNPcvXVV1t1Ot+/3L/+9S9efvllXn31VU4++WTy8vLIyckhIyODMWPGWHU61/XjaM5rXZx7XZ5rxFJTU4mJiamRjAsLC2ukbDlyEyZM4M033+Sjjz6iXbt21nq32w2g814HVq5cSWFhIVlZWcTGxhIbG8vChQv5xz/+QWxsrHU+da7rRps2bejevXvYum7durFp0yZA/7br0p/+9Cf+/Oc/c/nll9OjRw+ys7P54x//yLRp0wCd6/pSm/Pqdrvx+XwUFRUdsuZoKTQ1Yg6Hg6ysLBYsWBC2fsGCBfTr1y9CrYp+xhhuuukm/vOf//Dhhx/SqVOnsO2dOnXC7XaHnXefz8fChQt13o/QwIEDWb16NXl5edbSq1cvrrzySvLy8ujcubPOdR0666yzakyf8e2339KxY0dA/7brUnl5OXZ7+E9oTEyMNeWAznX9qM15zcrKIi4uLqwmPz+fNWvW/PJz/4uGkUu9q55y4LnnnjPr1q0zOTk5Jikpyfz000+RblrUuvHGG43L5TIff/yxyc/Pt5by8nKr5r777jMul8v85z//MatXrzZXXHGFbhWuI/vfPWeMznVdWr58uYmNjTX33nuv+e6778wrr7xiEhMTzcsvv2zV6HzXjTFjxpi2bdtaUw785z//MampqebWW2+1anSuj05paalZtWqVWbVqlQHMww8/bFatWmVNtVOb83rDDTeYdu3amffff9988cUX5le/+pWmHDhWPP7446Zjx47G4XCY008/3bo1Xo4OcNBl1qxZVk0wGDR33XWXcbvdxul0mnPPPdesXr06co1uQg4MTTrXdet///ufyczMNE6n05x00knmmWeeCduu8103SkpKzM0332w6dOhg4uPjTefOnc2dd95pvF6vVaNzfXQ++uijg/7f6DFjxhhjandeKyoqzE033WRatmxpEhISzPDhw82mTZt+cdtsxhjzy/qqRERERJo+jWkSERERqQWFJhEREZFaUGgSERERqQWFJhEREZFaUGgSERERqQWFJhEREZFaUGgSERERqQWFJhGRemSz2XjjjTci3QwRqQMKTSLSZI0dOxabzVZjGTp0aKSbJiJRKDbSDRARqU9Dhw5l1qxZYeucTmeEWiMi0Uw9TSLSpDmdTtxud9iSkpIChC6dPfnkk1xwwQUkJCTQqVMnXn/99bD9V69eza9+9SsSEhJo1aoV1113HXv27Amref755zn55JNxOp20adOGm266KWz7zp07ueiii0hMTKRLly68+eab9fulRaReKDSJyDHtr3/9K7/5zW/48ssvueqqq7jiiiv4+uuvASgvL2fo0KGkpKSwYsUKXn/9dd5///2wUPTkk0/yhz/8geuuu47Vq1fz5ptvcsIJJ4R9xt13382ll17KV199xYUXXsiVV17J7t27G/R7ikgd+MWP/BURaaTGjBljYmJiTFJSUthyzz33GGOMAcwNN9wQtk/v3r3NjTfeaIwx5plnnjEpKSlmz5491va3337b2O12U1BQYIwxJiMjw9x5552HbANg/vKXv1jv9+zZY2w2m3n33Xfr7HuKSMPQmCYRadLOO+88nnzyybB1LVu2tF737ds3bFvfvn3Jy8sD4Ouvv+aUU04hKSnJ2n7WWWcRDAb55ptvsNlsbNu2jYEDBx62DT179rReJyUlkZycTGFh4dF+JRGJEIUmEWnSkpKSalwu+zk2mw0AY4z1+mA1CQkJtTpeXFxcjX2DweARtUlEIk9jmkTkmLZ06dIa70866SQAunfvTl5eHmVlZdb2zz77DLvdzoknnkhycjLHHXccH3zwQYO2WUQiQz1NItKkeb1eCgoKwtbFxsaSmpoKwOuvv06vXr04++yzeeWVV1i+fDnPPfccAFdeeSV33XUXY8aMYcqUKezYsYMJEyaQnZ1Neno6AFOmTOGGG24gLS2NCy64gNLSUj777DMmTJjQsF9UROqdQpOINGnz5s2jTZs2Yeu6du3K+vXrgdCdbbm5uYwfPx63280rr7xC9+7dAUhMTOS9997j5ptv5owzziAxMZHf/OY3PPzww9axxowZQ2VlJTNmzGDy5MmkpqZyySWXNNwXFJEGYzPGmEg3QkQkEmw2G3PnzmXUqFGRboqIRAGNaRIRERGpBYUmERERkVrQmCYROWZpdIKIHAn1NImIiIjUgkKTiIiISC0oNImIiIjUgkKTiIiISC0oNImIiIjUgkKTiIiISC0oNImIiIjUgkKTiIiISC0oNImIiIjUwv8Hrwe0a4L5G1YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Val'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Adicionar regularizacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 12, but received input with shape (None, 9)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 9), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m Sequential([Dense(\u001b[38;5;241m100\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,)),Dense(\u001b[38;5;241m100\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),Dense(\u001b[38;5;241m100\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),Dense(\u001b[38;5;241m100\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m),])\n\u001b[0;32m      2\u001b[0m model_2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m hist_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(X_val, Y_val))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(hist_2\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(hist_2\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\julig\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\julig\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 12, but received input with shape (None, 9)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 9), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential([Dense(100, activation='relu', input_shape=(12,)),Dense(100, activation='relu'),Dense(100, activation='relu'),Dense(100, activation='relu'),Dense(1, activation='sigmoid'),])\n",
    "model_2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist_2 = model_2.fit(X_train, Y_train,batch_size=32, epochs=15,validation_data=(X_val, Y_val))\n",
    "plt.plot(hist_2.history['loss'])\n",
    "plt.plot(hist_2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'r2_score' from 'sklearn.base' (c:\\Users\\julig\\anaconda3\\Lib\\site-packages\\sklearn\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#preddcion \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#metricas de error\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'r2_score' from 'sklearn.base' (c:\\Users\\julig\\anaconda3\\Lib\\site-packages\\sklearn\\base.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "#preddcion \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#metricas de error\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mape = np.mean(np.abs((Y_test - y_pred) / Y_test))*100\n",
    "\n",
    "print(f'MAE:{mae}')\n",
    "print(f'MAE:{mse}')\n",
    "print(f'MAE:{rmse}')\n",
    "print(f'MAE:{r2}')\n",
    "print(f'MAE:{mape}')\n",
    "\n",
    "\n",
    "\n",
    "#caluar metricas de KeyError\n",
    "#mse \n",
    "#coeficiente de determinacion cercano a 1\n",
    "#districucion \n",
    "#y_pred - Y_test\n",
    "\n",
    "\n",
    "\n",
    "#jupiter notebooks\n",
    "#semana 12\n",
    "#Video\n",
    "\n",
    "\n",
    "#reviusar formato.\n",
    "#revisar columnas adecuadas\n",
    "#datos que se envian al entrenamineto\n",
    "#metrica binary coseentropy es la que deberia ?\n",
    "#mse->\n",
    "#mae->\n",
    "\n",
    "#probar con arinma?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# puedo hacert escalamiento con estandar escaler, min max, pero hay otras fornmas\n",
    "#cuando escalo al final debo desescalar para utilizar las mismas unidades del inico\n",
    "\n",
    "\n",
    "\n",
    "##cuando entreno un modelo y observo que el valor de validation val empieza a crecer graficamnete el modelo se empiezxa a sobreajustar\n",
    "##entonces debo hajustar la cantidad de iteraciones.\n",
    "\n",
    "\n",
    "\n",
    "#el tamano de la red importa incluso es mejor menos neuronas que muchas \n",
    "\n",
    "#debo agregar regularizacion\n",
    "\n",
    "\n",
    "#tener un numero de neuronas en la entrada debe corresponder al numnero de variables que utiliza mi dataset o numero de clases que utiliza el dataset\n",
    "\n",
    "#entrada numero de var\n",
    "# capa oculta 2^n \n",
    "#capa de salida 1\n",
    "\n",
    "#Ejemplos Entrada 3 6 1\n",
    "\n",
    "# con dos capas ocultas\n",
    "# 3 32 16 1\n",
    "#para la segunda capa es bueno dejar la mitad del numero de la primera capa   E  32 --> 16 S     E  8 -->4 S\n",
    "\n",
    "# optimizadores\n",
    "#loss=binary_crossentropy -> valores categioricos\n",
    "#loss = mse -> valores reales (Numericos)\n",
    "\n",
    "\n",
    "\n",
    "#REgresion y clasifgiccaicon\n",
    "#MLPClassifier_network\n",
    "#MLP_regresor\n",
    "\n",
    "#matrizx de cionsfucion \n",
    "\n",
    "\n",
    "#tasas de regulariczacion \n",
    "\n",
    "#mean_squared_error\n",
    "\n",
    "\n",
    "#dividir coinjunto y prueba\n",
    "\n",
    "#partir escalar\n",
    "\n",
    "#entrenamientop\n",
    "\n",
    "#predicion\n",
    "\n",
    "\n",
    "\n",
    "#estar seguro clasificacion matriz de consucion\n",
    "#regfresion mse rmse \n",
    "#r2 \n",
    "#y graficar distribucion de errores\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizan red con base en el articulo:\n",
    "https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
